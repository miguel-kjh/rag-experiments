{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473b050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 10-27 12:08:27 [__init__.py:216] Automatically detected platform cuda.\n",
      "WARNING 10-27 12:08:27 [interface.py:391] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_from_disk\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d8b356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.8: Fast Qwen3 patching. Transformers: 4.56.2. vLLM: 0.10.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.9.8 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = MAX_LENGTH,\n",
    "    load_in_4bit = False,\n",
    "    load_in_8bit = False,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "RANK = 256\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = RANK,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = RANK*2,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = SEED,\n",
    "    use_rslora = False,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb336663",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e47c08f",
   "metadata": {},
   "source": [
    "### Simple dataset loading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6bb16e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400 documents.\n",
      "First document: page_content='Nombre: Alba Alonso\n",
      "Tel√©fono: 632 322 183' metadata={'id': '7500_1'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "dataset = pd.read_csv(\"../notebooks/data/contacts_docs.csv\")\n",
    "documents = []\n",
    "for index, row in dataset.iterrows():\n",
    "    doc = f\"Nombre: {row['name']}\\nTel√©fono: {row['phone']}\"\n",
    "    documents.append(Document(page_content=doc, metadata={\"id\": f\"{row['id']}\" } ))\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "print(f\"First document: {documents[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d5204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dataset_train = pd.read_csv(\"../notebooks/data/contacts_queries_train.csv\")\n",
    "query_dataset_val = pd.read_csv(\"../notebooks/data/contacts_queries_val.csv\")\n",
    "query_dataset_test = pd.read_csv(\"../notebooks/data/contacts_queries_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50f936fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {\n",
    "    \"train\": query_dataset_train,\n",
    "    \"validation\": query_dataset_val,\n",
    "    \"test\": query_dataset_test,\n",
    "}\n",
    "\n",
    "#to hugginface dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "dataset = {}\n",
    "for split in all_data:\n",
    "    dataset[split] = Dataset.from_pandas(all_data[split])\n",
    "dataset = DatasetDict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e7f1812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'id'],\n",
       "        num_rows: 1400\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'id'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'id'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae2c9014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 400 special ID tokens.\n"
     ]
    }
   ],
   "source": [
    "# === Option B: IDs como tokens especiales (DOCID:{...}) ===\n",
    "def collect_all_ids(ds):\n",
    "    ids = set()\n",
    "    for split in (\"train\", \"validation\", \"test\"):\n",
    "        if split in ds:\n",
    "            for ex in ds[split]:\n",
    "                if \"id\" in ex:\n",
    "                    ids.add(str(ex[\"id\"]))\n",
    "    return sorted(list(ids))\n",
    "\n",
    "all_ids = collect_all_ids(dataset)\n",
    "special_id_tokens = [f\"DOCID:{{{docid}}}\" for docid in all_ids]\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"<|pad|>\"})\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": special_id_tokens})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(f\"Added {len(special_id_tokens)} special ID tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aef7d329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params (LoRA + lm_head): 161480704\n"
     ]
    }
   ],
   "source": [
    "# === Habilitar entrenamiento del lm_head junto con LoRA en la fase autoregresiva ===\n",
    "for name, p in model.named_parameters():\n",
    "    p.requires_grad_(False)\n",
    "for name, p in model.named_parameters():\n",
    "    if \"lora_\" in name or \"lm_head\" in name:\n",
    "        p.requires_grad_(True)\n",
    "trainables = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Trainable params (LoRA + lm_head):\", trainables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c8d15a",
   "metadata": {},
   "source": [
    "### Real dataset loading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5b956a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    ")\n",
    "\n",
    "db = FAISS.load_local(\n",
    "    \"../data/db/parliament_db/parliament_all_docs_embeddings_sentence-transformers_paraphrase-multilingual-mpnet-base-v2\",\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "08fbfd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 11162\n"
     ]
    }
   ],
   "source": [
    "#quiero la lista de documentos\n",
    "docs = db.docstore._dict.values()\n",
    "documents = list(docs)\n",
    "print(f\"Number of documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cbda5e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'response', 'cost', 'documents', 'type', 'retrieved_pks', 'oracle_context', 'formatted_context'],\n",
       "        num_rows: 614\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question', 'response', 'cost', 'documents', 'type', 'retrieved_pks', 'oracle_context', 'formatted_context'],\n",
       "        num_rows: 161\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'id', 'response', 'type', 'retrieved_pks', 'oracle_context', 'injected_oracle', 'formatted_context', 'documents'],\n",
       "        num_rows: 205\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER_AUTORE = \"../data/processed/parliament_qa\"\n",
    "dataset = load_from_disk(FOLDER_AUTORE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1efe551",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "680e0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_it(tokenizer, system_prompt: str, prompt: str, response: str) -> str:\n",
    "    \"\"\"Builds the chat prompt for a single example using the tokenizer chat template.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\",   \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response}\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5126e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prompt_for_indexing(documents: list):\n",
    "    prompt = \"\"\"\n",
    "    Contenido del documento:\n",
    "    {doc}\n",
    "    El Identificador del documento es DOCID:{{{doc_id}}}\n",
    "    \"\"\"\n",
    "    for doc in documents:\n",
    "        document = doc.page_content\n",
    "        doc_id = doc.metadata.get(\"id\", \"unknown\")\n",
    "        yield prompt.format(doc=document, doc_id=doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d4d4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prompts_for_retrieval(dataset, tokenizer):\n",
    "    system_prompt = \"\"\"\n",
    "    Eres un m√≥dulo de recuperaci√≥n. Tu √∫nica tarea es devolver el identificador del documento correspondiente a la consulta dada.\n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    for item in dataset:\n",
    "        prompt = \"\"\"\n",
    "        Dada la siguiente consulta, recupera los identificadores de los documentos relevantes. \n",
    "        Consulta: {QUERY}\n",
    "        \"\"\"\n",
    "        response = \"DOCID:{{{docid}}}\"\n",
    "        question = item[\"question\"]\n",
    "        prompt = prompt.format(QUERY=question)\n",
    "        prompts.append(build_prompt_it(tokenizer, system_prompt, prompt, response.format(docid=item[\"id\"])))\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b744a024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prompts: 400\n"
     ]
    }
   ],
   "source": [
    "prompts = list(prepare_prompt_for_indexing(documents))\n",
    "print(f\"Number of prompts: {len(prompts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b9ed38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Contenido del documento:\\n    Nombre: Alba Alonso\\nTel√©fono: 632 322 183\\n    El Identificador del documento es DOCID:{7500_1}\\n    '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d86e8e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 48 \n",
      "\n",
      "Tokens: ['ƒä', 'ƒ†ƒ†ƒ†', 'ƒ†Cont', 'enido', 'ƒ†del', 'ƒ†documento', ':ƒä', 'ƒ†ƒ†ƒ†', 'ƒ†Nombre', ':', 'ƒ†Al', 'ba', 'ƒ†Alonso', 'ƒä', 'Tel', '√É¬©fono', ':', 'ƒ†', '6', '3', '2', 'ƒ†', '3', '2', '2', 'ƒ†', '1', '8', '3', 'ƒä', 'ƒ†ƒ†ƒ†', 'ƒ†El', 'ƒ†Ident', 'ificador', 'ƒ†del', 'ƒ†documento', 'ƒ†es', 'ƒ†DOC', 'ID', ':{', '7', '5', '0', '0', '_', '1', '}ƒä', 'ƒ†ƒ†ƒ†ƒ†']\n"
     ]
    }
   ],
   "source": [
    "# QUIERO VER LOS TOKENS\n",
    "def print_tokens(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    print(\"Number of tokens:\", len(tokens), \"\\n\")\n",
    "    print(\"Tokens:\", tokens)\n",
    "\n",
    "print_tokens(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed65b3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset from prompts\n",
    "from datasets import Dataset\n",
    "indexing_dataset = Dataset.from_dict({\"text\": prompts})\n",
    "indexing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cda96468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Contenido del documento:\\n    Nombre: Alba Alonso\\nTel√©fono: 632 322 183\\n    El Identificador del documento es DOCID:{7500_1}\\n    '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexing_dataset[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ee44269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of retrieval prompts: 1400\n",
      "Number of retrieval prompts: 300\n"
     ]
    }
   ],
   "source": [
    "prompts_retrieval_train = prepare_prompts_for_retrieval(dataset[\"train\"], tokenizer)\n",
    "prompts_retrieval_val = prepare_prompts_for_retrieval(dataset[\"validation\"], tokenizer)\n",
    "\n",
    "print(f\"Number of retrieval prompts: {len(prompts_retrieval_train)}\")\n",
    "print(f\"Number of retrieval prompts: {len(prompts_retrieval_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab6c0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "\n",
      "    Eres un m√≥dulo de recuperaci√≥n. Tu √∫nica tarea es devolver el identificador del documento correspondiente a la consulta dada.\n",
      "    <|im_end|>\n",
      "<|im_start|>user\n",
      "\n",
      "        Dada la siguiente consulta, recupera los identificadores de los documentos relevantes. \n",
      "        Consulta: Necesito el contacto asociado al 620 152 344. ‚Äîconsulta interna‚Äî\n",
      "        <|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "DOCID:{7503_3}<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompts_retrieval_train[0], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87e1cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 113 \n",
      "\n",
      "Tokens: ['<|im_start|>', 'system', 'ƒäƒä', 'ƒ†ƒ†ƒ†', 'ƒ†E', 'res', 'ƒ†un', 'ƒ†m', '√É¬≥d', 'ulo', 'ƒ†de', 'ƒ†recuper', 'aci√É¬≥n', '.', 'ƒ†Tu', 'ƒ†√É¬∫nica', 'ƒ†tarea', 'ƒ†es', 'ƒ†dev', 'olver', 'ƒ†el', 'ƒ†ident', 'ificador', 'ƒ†del', 'ƒ†documento', 'ƒ†correspond', 'iente', 'ƒ†a', 'ƒ†la', 'ƒ†consulta', 'ƒ†d', 'ada', '.ƒä', 'ƒ†ƒ†ƒ†ƒ†', '<|im_end|>', 'ƒä', '<|im_start|>', 'user', 'ƒäƒä', 'ƒ†ƒ†ƒ†ƒ†ƒ†ƒ†ƒ†', 'ƒ†D', 'ada', 'ƒ†la', 'ƒ†siguiente', 'ƒ†consulta', ',', 'ƒ†rec', 'up', 'era', 'ƒ†los', 'ƒ†ident', 'ific', 'adores', 'ƒ†de', 'ƒ†los', 'ƒ†documentos', 'ƒ†relevant', 'es', '.', 'ƒ†ƒä', 'ƒ†ƒ†ƒ†ƒ†ƒ†ƒ†ƒ†', 'ƒ†Consult', 'a', ':', 'ƒ†Nec', 'es', 'ito', 'ƒ†el', 'ƒ†contacto', 'ƒ†asoci', 'ado', 'ƒ†al', 'ƒ†', '6', '2', '0', 'ƒ†', '1', '5', '2', 'ƒ†', '3', '4', '4', '.', 'ƒ†√¢ƒ¢ƒ∂', 'consulta', 'ƒ†intern', 'a', '√¢ƒ¢ƒ∂', 'ƒä', 'ƒ†ƒ†ƒ†ƒ†ƒ†ƒ†ƒ†ƒ†', '<|im_end|>', 'ƒä', '<|im_start|>', 'assistant', 'ƒä', '<think>', 'ƒäƒä', '</think>', 'ƒäƒä', 'DOC', 'ID', ':{', '7', '5', '0', '3', '_', '3', '}', '<|im_end|>', 'ƒä']\n"
     ]
    }
   ],
   "source": [
    "print_tokens(prompts_retrieval_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97de98e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset from prompts train, val, test\n",
    "retrieval_train_dataset = Dataset.from_dict({\"text\": prompts_retrieval_train})\n",
    "retrieval_val_dataset = Dataset.from_dict({\"text\": prompts_retrieval_val})\n",
    "\n",
    "retrieval_dataset = {\n",
    "    \"train\": retrieval_train_dataset,\n",
    "    \"validation\": retrieval_val_dataset,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a87ecc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForCompletionOnlyLM:\n",
    "    tokenizer: object\n",
    "    response_template: str = \"<|im_start|>assistant\"\n",
    "    mlm: bool = False\n",
    "\n",
    "    def __call__(self, examples: List[Dict[str, str]]) -> Dict[str, torch.Tensor]:\n",
    "        texts = [ex for ex in examples]\n",
    "        tokenized = self.tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.tokenizer.model_max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        labels = tokenized.input_ids.clone()\n",
    "        # M√°scara: solo calcular p√©rdida en la parte del assistant\n",
    "        for i, text in enumerate(texts):\n",
    "            idx = text.find(self.response_template)\n",
    "            if idx != -1:\n",
    "                token_pos = self.tokenizer(text[:idx], add_special_tokens=False)[\"input_ids\"]\n",
    "                cutoff = len(token_pos)\n",
    "                labels[i, :cutoff] = -100\n",
    "        tokenized[\"labels\"] = labels\n",
    "        return tokenized\n",
    "    \n",
    "collator_it = DataCollatorForCompletionOnlyLM(\n",
    "    tokenizer=tokenizer,\n",
    "    response_template=\"<|im_start|>assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60314e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function_autoregressive(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a0505aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:00<00:00, 15598.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "indexing_dataset_tokenizer = indexing_dataset.map(tokenize_function_autoregressive, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "898f2e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1400/1400 [00:00<00:00, 17632.07 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 15482.28 examples/s]\n"
     ]
    }
   ],
   "source": [
    "retrieval_train_dataset_tokenizer = retrieval_dataset[\"train\"].map(tokenize_function_autoregressive, batched=True)\n",
    "retrieval_val_dataset_tokenizer = retrieval_dataset[\"validation\"].map(tokenize_function_autoregressive, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa230b46",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01d9a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sft training\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "auto_config = SFTConfig(\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 8, # Use GA to mimic batch size!\n",
    "    save_steps=5,\n",
    "    warmup_steps = 5,\n",
    "    num_train_epochs = 3, # Set this for 1 full training run.\n",
    "    #max_steps = 60,\n",
    "    learning_rate = 1e-4, # Reduce to 2e-5 for long training runs\n",
    "    logging_steps = 1,\n",
    "    # 32 bits\n",
    "    optim = \"paged_adamw_32bit\",\n",
    "    weight_decay = 0.01,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    seed = SEED,\n",
    "    report_to = \"none\", # Use this for WandB etc\n",
    "    output_dir=\"../models/qwen3-0.6b-rag-indexer\",\n",
    ")\n",
    "\n",
    "it_config = SFTConfig(\n",
    "    dataset_text_field=\"text\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,         # <-- a√±ade eval batch size\n",
    "    gradient_accumulation_steps=16,\n",
    "    warmup_steps=25,\n",
    "    save_steps=25,\n",
    "    eval_steps=1,\n",
    "    eval_strategy=\"steps\",         # <-- activa evaluaci√≥n peri√≥dica\n",
    "    num_train_epochs=1,             # <-- opcional: usa epochs en lugar de max_steps\n",
    "    #max_steps=30,\n",
    "    learning_rate=1e-4,\n",
    "    logging_steps=1,\n",
    "    optim = \"paged_adamw_32bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=SEED,\n",
    "    report_to=\"none\",\n",
    "    output_dir=\"../models/qwen3-0.6b-rag-retriever\",\n",
    "    load_best_model_at_end=True,          # <-- opcional\n",
    "    metric_for_best_model=\"eval_loss\",    # <-- opcional\n",
    "    greater_is_better=False,              # <-- opcional\n",
    ")\n",
    "\n",
    "trainer_auto = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=indexing_dataset_tokenizer,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    args=auto_config,\n",
    ")\n",
    "\n",
    "trainer_it = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=retrieval_train_dataset_tokenizer,\n",
    "    eval_dataset=retrieval_val_dataset_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    args=it_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "176683a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4090. Max memory = 23.988 GB.\n",
      "1.752 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b15ec644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 161,480,704 || all params: 757,666,816 || trainable%: 21.3129\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f708de6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 3 | Total steps = 21\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 161,480,704 of 757,530,624 (21.32% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.957900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.950200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.835100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.790300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.852100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.768200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.767700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.801800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.729800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.699400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.700900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.692100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.688100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.678800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.690500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.679700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.674500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,400 | Num Epochs = 1 | Total steps = 6\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 16 x 1) = 256\n",
      " \"-____-\"     Trainable parameters = 161,480,704 of 757,530,624 (21.32% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.654200</td>\n",
       "      <td>5.682090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.691500</td>\n",
       "      <td>4.872732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.874500</td>\n",
       "      <td>3.791305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.780800</td>\n",
       "      <td>2.809565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.815400</td>\n",
       "      <td>2.064784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.036900</td>\n",
       "      <td>1.486922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but Qwen3ForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 3 | Total steps = 21\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 161,480,704 of 757,530,624 (21.32% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.721500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.719900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.672300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.686200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.687600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.689600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.667100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.687700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.686300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.681300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.678700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.670400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.672100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.674400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.671200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.666800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.671400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.656400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,400 | Num Epochs = 1 | Total steps = 6\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 16 x 1) = 256\n",
      " \"-____-\"     Trainable parameters = 161,480,704 of 757,530,624 (21.32% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.457800</td>\n",
       "      <td>2.491342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.464800</td>\n",
       "      <td>2.227789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.218200</td>\n",
       "      <td>1.777558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.757300</td>\n",
       "      <td>1.371486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.371100</td>\n",
       "      <td>1.075885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.046000</td>\n",
       "      <td>0.865046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 3 | Total steps = 21\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 161,480,704 of 757,530,624 (21.32% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.667600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.669300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.661900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.661900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.673000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.674600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.656700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.661400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.682600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.676500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.675800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.673900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.674400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.663200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.666500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.663800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.661600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.664700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.644300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,400 | Num Epochs = 1 | Total steps = 6\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 16 x 1) = 256\n",
      " \"-____-\"     Trainable parameters = 161,480,704 of 757,530,624 (21.32% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.957675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.927400</td>\n",
       "      <td>0.896505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.889300</td>\n",
       "      <td>0.792751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.778400</td>\n",
       "      <td>0.678473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.596149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.571100</td>\n",
       "      <td>0.520629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 3 | Total steps = 21\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 161,480,704 of 757,530,624 (21.32% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.661000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.657600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.658300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.666100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.669800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.653100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.668400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.670900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.673000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.672600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.669000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.652600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.657400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.664700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.661700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.654800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.661400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.627900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,400 | Num Epochs = 1 | Total steps = 6\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 16 x 1) = 256\n",
      " \"-____-\"     Trainable parameters = 161,480,704 of 757,530,624 (21.32% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.554000</td>\n",
       "      <td>0.573930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.547400</td>\n",
       "      <td>0.557318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.547400</td>\n",
       "      <td>0.528936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.516400</td>\n",
       "      <td>0.484950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.482100</td>\n",
       "      <td>0.436128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.417800</td>\n",
       "      <td>0.394163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 4\n",
    "for _ in range(EPOCHS):\n",
    "    trainer_sft_stats = trainer_auto.train() # (context, id)\n",
    "    trainer_it_stats = trainer_it.train() # (query, id)\n",
    "    # GUARDAR MODELOS CADA SUPER EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7333bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 161,480,704 || all params: 757,530,624 || trainable%: 21.3167\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d6735bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak reserved memory = 4.977 GB.\n",
      "Peak reserved memory for training = 3.225 GB.\n",
      "Peak reserved memory % of max memory = 20.748 %.\n",
      "Peak reserved memory for training % of max memory = 13.444 %.\n"
     ]
    }
   ],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d51434cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prompts_for_testing(dataset, tokenizer):\n",
    "    system_prompt = \"\"\"\n",
    "    Eres un m√≥dulo de recuperaci√≥n. Tu √∫nica tarea es devolver el identificador del documento correspondiente a la consulta dada.\n",
    "    \"\"\"\n",
    "    def build_prompt_it(tokenizer, system_prompt: str, prompt: str) -> str:\n",
    "        \"\"\"Builds the chat prompt for a single example using the tokenizer chat template.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\",   \"content\": prompt},\n",
    "        ]\n",
    "        return tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False,\n",
    "        )\n",
    "    prompts = []\n",
    "    for item in dataset:\n",
    "        prompt = \"\"\"\n",
    "        Dada la siguiente consulta, recupera los identificadores de los documentos relevantes. \n",
    "        Consulta: {QUERY}\n",
    "        \"\"\"\n",
    "        question = item[\"question\"]\n",
    "        prompt = prompt.format(QUERY=question)\n",
    "        prompts.append(\n",
    "            ( \n",
    "                build_prompt_it(tokenizer, system_prompt, prompt),\n",
    "                item[\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4f12665",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_retrieval_test = prepare_prompts_for_testing(dataset[\"test\"], tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ba62589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7538_1\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "text = prompts_retrieval_test[i][0]\n",
    "doc_id_targets = prompts_retrieval_test[i][1]\n",
    "print(doc_id_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43cbeadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "\n",
      "    Eres un m√≥dulo de recuperaci√≥n. Tu √∫nica tarea es devolver el identificador del documento correspondiente a la consulta dada.\n",
      "    <|im_end|>\n",
      "<|im_start|>user\n",
      "\n",
      "        Dada la siguiente consulta, recupera los identificadores de los documentos relevantes. \n",
      "        Consulta: Dame el n√∫mero de Manuel S√°nchez.\n",
      "        <|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47228fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "DOCID:{7515_2}<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "# test the model in streaming mode\n",
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=False)\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 64, # Increase for longer outputs!\n",
    "    do_sample = False,\n",
    "    top_p = 0.1,\n",
    "    temperature = 0.,\n",
    "    streamer = streamer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "495dc274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DOCID:{7521_2}<|im_end|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# extract DOCID number using regex\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m doc_id \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDOCID:(\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+_\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrect:\u001b[39m\u001b[38;5;124m\"\u001b[39m, doc_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted:\u001b[39m\u001b[38;5;124m\"\u001b[39m, doc_id_target)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc_id \u001b[38;5;241m==\u001b[39m doc_id_target:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "# test the model in non-streaming mode\n",
    "import re\n",
    "import tqdm\n",
    "\n",
    "acc = 0\n",
    "total = 0\n",
    "\n",
    "for text, doc_id_target in tqdm.tqdm(prompts_retrieval_test, desc=\"Testing\"):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=64,  # Increase for longer outputs!\n",
    "        do_sample=False, temperature=0.0, top_p=1.0\n",
    "    )\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    response = generated_text.split(\"</think>\")[-1]\n",
    "    print(response)\n",
    "    # extract DOCID number using regex\n",
    "\n",
    "    doc_id = re.search(r\"DOCID:(\\d+_\\d+)\", response).group(1)\n",
    "    \n",
    "    print(\"Correct:\", doc_id, \"==\", \"Predicted:\", doc_id_target)\n",
    "    if doc_id == doc_id_target:\n",
    "        acc += 1\n",
    "    total += 1\n",
    "print(f\"Accuracy: {acc}/{total} = {acc/total*100:.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
