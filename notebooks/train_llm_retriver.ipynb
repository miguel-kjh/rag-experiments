{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473b050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 11-05 16:01:40 [__init__.py:216] Automatically detected platform cuda.\n",
      "WARNING 11-05 16:01:40 [interface.py:391] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9d8b356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.8: Fast Llama patching. Transformers: 4.56.2. vLLM: 0.10.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B-instruct\"\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = MAX_LENGTH,\n",
    "    full_finetuning=False,\n",
    "    load_in_4bit = False,\n",
    "    load_in_8bit = False,\n",
    ")\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "RANK = 512\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = RANK,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = RANK*2,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = SEED,\n",
    "    use_rslora = False,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb336663",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76840c6e",
   "metadata": {},
   "source": [
    "### tel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14661458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset_qa = load_from_disk(\"../notebooks/data/dataset_instruct_train/\")\n",
    "# create validation dataset from dataset_qa\n",
    "dataset_qa = dataset_qa.train_test_split(test_size=0.1, seed=SEED)\n",
    "dataset_knowledge = load_from_disk(\"../notebooks/data/dataset_telephones\")\n",
    "\n",
    "documents = list(dataset_knowledge[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e47c08f",
   "metadata": {},
   "source": [
    "### Simple dataset loading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6bb16e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400 documents.\n",
      "First document: page_content='Nombre: Alba Alonso\n",
      "TelÃ©fono: 632 322 183' metadata={'id': '7500_1'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "dataset_knowledge = pd.read_csv(\"../notebooks/data/contacts_docs.csv\")\n",
    "documents = []\n",
    "for index, row in dataset_knowledge.iterrows():\n",
    "    doc = f\"Nombre: {row['name']}\\nTelÃ©fono: {row['phone']}\"\n",
    "    documents.append(Document(page_content=doc, metadata={\"id\": f\"{row['id']}\" } ))\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "print(f\"First document: {documents[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d5204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dataset_train = pd.read_csv(\"../notebooks/data/contacts_queries_train.csv\")\n",
    "query_dataset_val = pd.read_csv(\"../notebooks/data/contacts_queries_val.csv\")\n",
    "query_dataset_test = pd.read_csv(\"../notebooks/data/contacts_queries_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50f936fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {\n",
    "    \"train\": query_dataset_train,\n",
    "    \"validation\": query_dataset_val,\n",
    "    \"test\": query_dataset_test,\n",
    "}\n",
    "\n",
    "#to hugginface dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "dataset_qa = {}\n",
    "for split in all_data:\n",
    "    dataset_qa[split] = Dataset.from_pandas(all_data[split])\n",
    "dataset_qa = DatasetDict(dataset_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e7f1812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'id', 'respuesta'],\n",
       "        num_rows: 1400\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'id', 'respuesta'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'id', 'respuesta'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7952bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN TRAIN AND VAL DATASETS\n",
    "from datasets import concatenate_datasets\n",
    "dataset_qa[\"train\"] = concatenate_datasets([dataset_qa[\"train\"], dataset_qa[\"validation\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "950c17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename \"respuesta\" column to \"answer\"\n",
    "dataset_qa = dataset_qa.rename_column(\"respuesta\", \"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c12e213c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'id', 'answer'],\n",
       "        num_rows: 1700\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'id', 'answer'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'id', 'answer'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1efe551",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680e0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_it(tokenizer, system_prompt: str, prompt: str, response: str) -> str:\n",
    "    \"\"\"Builds the chat prompt for a single example using the tokenizer chat template.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\",   \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response}\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5126e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_knowledge_injection_prompts(documents: list):\n",
    "    prompt = \"\"\"{doc}\"\"\"\n",
    "    for doc in documents:\n",
    "        yield prompt.format(doc=doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d4d4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_prompts(dataset, tokenizer):\n",
    "    system_prompt = \"\"\"\n",
    "    Eres un modelo de lenguaje entrenado para responder preguntas.\n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    for item in dataset:\n",
    "        prompt = \"\"\"{QUERY}\"\"\"\n",
    "        response = \"{response}\"\n",
    "        question = item[\"question\"]\n",
    "        prompt = prompt.format(QUERY=question)\n",
    "        prompts.append(build_prompt_it(tokenizer, system_prompt, prompt, response.format(response=item[\"answer\"])))\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b744a024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prompts: 400\n"
     ]
    }
   ],
   "source": [
    "prompts = list(generate_knowledge_injection_prompts(documents))\n",
    "print(f\"Number of prompts: {len(prompts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7b9ed38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nombre: Alba Alonso\\nTelÃ©fono: 632 322 183'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d86e8e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 15 \n",
      "\n",
      "Tokens: ['Nombre', ':', 'Ä Al', 'ba', 'Ä Alonso', 'ÄŠ', 'Tel', 'ÃƒÂ©fono', ':', 'Ä ', '632', 'Ä ', '322', 'Ä ', '183']\n"
     ]
    }
   ],
   "source": [
    "# QUIERO VER LOS TOKENS\n",
    "def print_tokens(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    print(\"Number of tokens:\", len(tokens), \"\\n\")\n",
    "    print(\"Tokens:\", tokens)\n",
    "\n",
    "print_tokens(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed65b3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset from prompts\n",
    "from datasets import Dataset\n",
    "knowledge_dataset = Dataset.from_dict({\"text\": prompts})\n",
    "knowledge_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cda96468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nombre: Alba Alonso\\nTelÃ©fono: 632 322 183'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_dataset[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ee44269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of retrieval prompts: 1700\n",
      "Number of retrieval prompts: 300\n"
     ]
    }
   ],
   "source": [
    "prompts_qa_train = generate_qa_prompts(dataset_qa[\"train\"], tokenizer)\n",
    "prompts_qa_val = generate_qa_prompts(dataset_qa[\"test\"], tokenizer)\n",
    "\n",
    "print(f\"Number of retrieval prompts: {len(prompts_qa_train)}\")\n",
    "print(f\"Number of retrieval prompts: {len(prompts_qa_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ab6c0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 05 Nov 2025\n",
      "\n",
      "Eres un modelo de lenguaje entrenado para responder preguntas.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Necesito el contacto asociado al 620 152 344. â€”consulta internaâ€”<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "El nÃºmero 620 152 344 pertenece a Alejandro Vega.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(prompts_qa_train[0], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87e1cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 87 \n",
      "\n",
      "Tokens: ['<|begin_of_text|>', '<|start_header_id|>', 'system', '<|end_header_id|>', 'ÄŠÄŠ', 'Cut', 'ting', 'Ä Knowledge', 'Ä Date', ':', 'Ä December', 'Ä ', '202', '3', 'ÄŠ', 'Today', 'Ä Date', ':', 'Ä ', '05', 'Ä Nov', 'Ä ', '202', '5', 'ÄŠÄŠ', 'E', 'res', 'Ä un', 'Ä modelo', 'Ä de', 'Ä l', 'engu', 'aje', 'Ä entren', 'ado', 'Ä para', 'Ä responder', 'Ä preg', 'untas', '.', '<|eot_id|>', '<|start_header_id|>', 'user', '<|end_header_id|>', 'ÄŠÄŠ', 'N', 'ec', 'es', 'ito', 'Ä el', 'Ä contacto', 'Ä asoci', 'ado', 'Ä al', 'Ä ', '620', 'Ä ', '152', 'Ä ', '344', '.', 'Ä Ã¢Ä¢Ä¶', 'consulta', 'Ä intern', 'a', 'Ã¢Ä¢Ä¶', '<|eot_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', 'ÄŠÄŠ', 'El', 'Ä nÃƒÂºmero', 'Ä ', '620', 'Ä ', '152', 'Ä ', '344', 'Ä pert', 'ene', 'ce', 'Ä a', 'Ä Alejandro', 'Ä Vega', '.', '<|eot_id|>']\n"
     ]
    }
   ],
   "source": [
    "print_tokens(prompts_qa_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97de98e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset from prompts train, val, test\n",
    "qa_train_dataset = Dataset.from_dict({\"text\": prompts_qa_train})\n",
    "qa_val_dataset = Dataset.from_dict({\"text\": prompts_qa_val})\n",
    "\n",
    "qa_dataset = {\n",
    "    \"train\": qa_train_dataset,\n",
    "    \"validation\": qa_val_dataset,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60314e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function_autoregressive(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a0505aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:00<00:00, 14645.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "knowledge_dataset_tokenizer = knowledge_dataset.map(tokenize_function_autoregressive, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "898f2e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1700/1700 [00:00<00:00, 19569.64 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 16041.04 examples/s]\n"
     ]
    }
   ],
   "source": [
    "qa_train_dataset_tokenizer = qa_dataset[\"train\"].map(tokenize_function_autoregressive, batched=True)\n",
    "qa_val_dataset_tokenizer = qa_dataset[\"validation\"].map(tokenize_function_autoregressive, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7136411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_prompts_testing(dataset, tokenizer):\n",
    "    def build_prompt_it_generation(tokenizer, system_prompt: str, prompt: str) -> str:\n",
    "        \"\"\"Builds the chat prompt for a single example using the tokenizer chat template.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\",   \"content\": prompt},\n",
    "        ]\n",
    "        return tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False,\n",
    "        )\n",
    "    system_prompt = \"\"\"\n",
    "    Eres un modelo de lenguaje entrenado para responder preguntas.\n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    for item in dataset:\n",
    "        prompt = \"\"\"{QUERY}\"\"\"\n",
    "        question = item[\"question\"]\n",
    "        answer = item[\"answer\"]\n",
    "        prompt = prompt.format(QUERY=question)\n",
    "        prompts.append(\n",
    "            (\n",
    "                build_prompt_it_generation(tokenizer, system_prompt, prompt),\n",
    "                answer,\n",
    "            )\n",
    "        )\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8379bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 05 Nov 2025\n",
      "\n",
      "Eres un modelo de lenguaje entrenado para responder preguntas.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Â¿A quiÃ©n pertenece el telÃ©fono 736 615 948?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts_retrieval_test = generate_qa_prompts_testing(dataset_qa[\"test\"], tokenizer)\n",
    "text_for_testing = prompts_retrieval_test[0][0]\n",
    "print(text_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4632b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "import torch\n",
    "\n",
    "def test_model_accuracy(model, tokenizer, prompts_retrieval_test, device=\"cuda\", \n",
    "                        max_new_tokens=64, temperature=0.0, top_p=1.0):\n",
    "    \n",
    "    acc = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm.tqdm(prompts_retrieval_test, desc=\"Testing\")\n",
    "\n",
    "    for text, answer in progress_bar:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p\n",
    "            )\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        response = generated_text.split(\"assistant\")[-1].strip()\n",
    "\n",
    "        if response == answer:\n",
    "            acc += 1\n",
    "        total += 1\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            \"acc\": f\"{acc/total*100:.2f} %\"\n",
    "        })\n",
    "\n",
    "    final_acc = acc / total * 100 if total > 0 else 0.0\n",
    "    print(f\"Accuracy final: {acc}/{total} = {final_acc:.2f} %\")\n",
    "    return final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18dd53aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Genera grÃ¡ficos de la evoluciÃ³n de la accuracy y las pÃ©rdidas (SFT e IT) durante el entrenamiento.\n",
    "\n",
    "    ParÃ¡metros:\n",
    "        history (list[dict]): lista de diccionarios, donde cada elemento debe contener:\n",
    "            - \"super_epoch\": nÃºmero de super-Ã©poca.\n",
    "            - \"accuracy\": precisiÃ³n alcanzada.\n",
    "            - \"trainer_sft_stats\".training_loss: pÃ©rdida SFT.\n",
    "            - \"trainer_it_stats\".training_loss: pÃ©rdida IT.\n",
    "    \"\"\"\n",
    "    # Extraer mÃ©tricas del historial\n",
    "    super_epochs = [h[\"super_epoch\"] for h in history]\n",
    "    accuracies = [h[\"accuracy\"] for h in history]\n",
    "    losses_sft = [h[\"trainer_sft_stats\"].training_loss for h in history]\n",
    "    losses_it = [h[\"trainer_it_stats\"].training_loss for h in history]\n",
    "\n",
    "    # --- GrÃ¡fico de Accuracy ---\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(super_epochs, accuracies, marker='o', color='tab:blue')\n",
    "    plt.xlabel(\"Super Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Accuracy History\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- GrÃ¡fico de Losses ---\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(super_epochs, losses_sft, marker='o', label=\"SFT Loss\", color='tab:orange')\n",
    "    plt.plot(super_epochs, losses_it, marker='s', label=\"IT Loss\", color='tab:green')\n",
    "    plt.xlabel(\"Super Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss History\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa230b46",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace130b",
   "metadata": {},
   "source": [
    "### Iterative training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01d9a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sft training\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "auto_config = UnslothTrainingArguments(\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 8, # Use GA to mimic batch size!\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=0,\n",
    "    warmup_steps = 5,\n",
    "    num_train_epochs = 1, # Set this for 1 full training run.\n",
    "    #max_steps = 60,\n",
    "    learning_rate = 1e-4, # Reduce to 2e-5 for long training runs\n",
    "    logging_steps = 1,\n",
    "    # 32 bits\n",
    "    optim = \"paged_adamw_32bit\",\n",
    "    weight_decay = 0.01,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    seed = SEED,\n",
    "    report_to = \"none\", # Use this for WandB etc\n",
    "    output_dir=\"../models/qwen3-0.6b-rag-indexer\",\n",
    ")\n",
    "\n",
    "it_config = SFTConfig(\n",
    "    dataset_text_field=\"text\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,        # <-- aÃ±ade eval batch size\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=25,\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=0,\n",
    "    eval_steps=1,\n",
    "    eval_strategy=\"steps\",         # <-- activa evaluaciÃ³n periÃ³dica\n",
    "    num_train_epochs=1,             # <-- opcional: usa epochs en lugar de max_steps\n",
    "    #max_steps=30,\n",
    "    learning_rate=1e-4,\n",
    "    logging_steps=1,\n",
    "    optim = \"paged_adamw_32bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=SEED,\n",
    "    report_to=\"none\",\n",
    "    output_dir=\"../models/qwen3-0.6b-rag-retriever\",\n",
    "    load_best_model_at_end=False,          # <-- opcional\n",
    "    metric_for_best_model=\"eval_loss\",    # <-- opcional\n",
    "    greater_is_better=False,              # <-- opcional\n",
    ")\n",
    "\n",
    "trainer_auto = UnslothTrainer(\n",
    "    model=model,\n",
    "    train_dataset=knowledge_dataset_tokenizer,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    args=auto_config,\n",
    ")\n",
    "\n",
    "trainer_it = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=qa_train_dataset_tokenizer,\n",
    "    eval_dataset=qa_val_dataset_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    args=it_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b15ec644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 360,710,144 || all params: 1,596,524,544 || trainable%: 22.5935\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f708de6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 1 | Total steps = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SUPER EPOCH 1 / 10 ---\n",
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.325900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.296200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.141900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.794800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.250100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.886700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.923700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,700 | Num Epochs = 1 | Total steps = 27\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 02:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.435800</td>\n",
       "      <td>5.437668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.384600</td>\n",
       "      <td>4.394589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.390800</td>\n",
       "      <td>3.340816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.300200</td>\n",
       "      <td>2.516832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.496800</td>\n",
       "      <td>1.952396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.947700</td>\n",
       "      <td>1.422426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.387500</td>\n",
       "      <td>1.111317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.100200</td>\n",
       "      <td>0.878597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.908800</td>\n",
       "      <td>0.770820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.794300</td>\n",
       "      <td>0.719856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.721600</td>\n",
       "      <td>0.695662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.686400</td>\n",
       "      <td>0.649878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.655861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.648900</td>\n",
       "      <td>0.621069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>0.606614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.601800</td>\n",
       "      <td>0.585074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>0.576920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.581100</td>\n",
       "      <td>0.547877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.550400</td>\n",
       "      <td>0.517469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>0.458101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.459100</td>\n",
       "      <td>0.397087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>0.389218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.391500</td>\n",
       "      <td>0.386920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.387380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.383800</td>\n",
       "      <td>0.387069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.387300</td>\n",
       "      <td>0.380285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.375100</td>\n",
       "      <td>0.375827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n",
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:25<00:00,  3.53it/s, acc=0.00 %]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final: 0/300 = 0.00 %\n",
      "Accuracy: 0.00 %\n",
      "--- SUPER EPOCH 2 / 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 1 | Total steps = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.585500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.560600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.285100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.159200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.662200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,700 | Num Epochs = 1 | Total steps = 27\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 02:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.839800</td>\n",
       "      <td>0.836634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.835200</td>\n",
       "      <td>0.771902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.777300</td>\n",
       "      <td>0.631360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.623300</td>\n",
       "      <td>0.533320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.511222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.495143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.495400</td>\n",
       "      <td>0.475509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.499686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.497600</td>\n",
       "      <td>0.455014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.443395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.442300</td>\n",
       "      <td>0.425365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.398307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.381058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>0.372615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>0.372488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>0.371557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.362700</td>\n",
       "      <td>0.368662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.375365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.375641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.354700</td>\n",
       "      <td>0.374590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.374960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.373361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.372600</td>\n",
       "      <td>0.372389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.368600</td>\n",
       "      <td>0.373291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.372560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>0.370893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.359300</td>\n",
       "      <td>0.368654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:29<00:00,  3.35it/s, acc=0.00 %]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final: 0/300 = 0.00 %\n",
      "Accuracy: 0.00 %\n",
      "--- SUPER EPOCH 3 / 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 1 | Total steps = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.912300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.897300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.338700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.089800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.598600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,700 | Num Epochs = 1 | Total steps = 27\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 02:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.399400</td>\n",
       "      <td>0.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.400600</td>\n",
       "      <td>0.392303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.393600</td>\n",
       "      <td>0.388491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.386500</td>\n",
       "      <td>0.384447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.379683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.387300</td>\n",
       "      <td>0.374142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>0.370768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.366695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.360301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.372300</td>\n",
       "      <td>0.354022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.356600</td>\n",
       "      <td>0.348297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.346200</td>\n",
       "      <td>0.341412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.346600</td>\n",
       "      <td>0.337039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.336279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.335169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.330164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.324327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.320331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.315400</td>\n",
       "      <td>0.315563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.282800</td>\n",
       "      <td>0.312969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.301900</td>\n",
       "      <td>0.306875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.299155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.294700</td>\n",
       "      <td>0.293036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.288145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.285710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.277600</td>\n",
       "      <td>0.283398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>0.279079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:28<00:00,  3.40it/s, acc=0.00 %]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final: 0/300 = 0.00 %\n",
      "Accuracy: 0.00 %\n",
      "--- SUPER EPOCH 4 / 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 1 | Total steps = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.108500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.955700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.754800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.465700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.753600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,700 | Num Epochs = 1 | Total steps = 27\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 02:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.326400</td>\n",
       "      <td>0.334522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.328100</td>\n",
       "      <td>0.333232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.329100</td>\n",
       "      <td>0.324542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>0.312048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.305300</td>\n",
       "      <td>0.292770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.272556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.268200</td>\n",
       "      <td>0.254531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.245700</td>\n",
       "      <td>0.242147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.234800</td>\n",
       "      <td>0.236689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.235259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.226800</td>\n",
       "      <td>0.236248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.235608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>0.233242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.230821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.233200</td>\n",
       "      <td>0.230105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.219400</td>\n",
       "      <td>0.232840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.221300</td>\n",
       "      <td>0.234740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>0.236852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>0.239470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.242968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.244720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.226100</td>\n",
       "      <td>0.241974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.238320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>0.237442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.222100</td>\n",
       "      <td>0.238191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.237258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.234900</td>\n",
       "      <td>0.235923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:22<00:00,  3.65it/s, acc=0.33 %]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final: 1/300 = 0.33 %\n",
      "Accuracy: 0.33 %\n",
      "--- SUPER EPOCH 5 / 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 1 | Total steps = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.249400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.255200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.161800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.859800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.640800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.214000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,700 | Num Epochs = 1 | Total steps = 27\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 02:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.159300</td>\n",
       "      <td>1.164124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.161900</td>\n",
       "      <td>0.990628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>0.858539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.853600</td>\n",
       "      <td>0.653342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.645800</td>\n",
       "      <td>0.259646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.322773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.321300</td>\n",
       "      <td>0.231389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.219400</td>\n",
       "      <td>0.229344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>0.226438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.223157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.220404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.219384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.219958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.205800</td>\n",
       "      <td>0.220637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.205600</td>\n",
       "      <td>0.220560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>0.219544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.195900</td>\n",
       "      <td>0.220193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>0.221676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.211700</td>\n",
       "      <td>0.222146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.192900</td>\n",
       "      <td>0.224562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.206100</td>\n",
       "      <td>0.224830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.224877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.225985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.225047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.223098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.222203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.213800</td>\n",
       "      <td>0.222942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:29<00:00,  3.35it/s, acc=9.00 %] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final: 27/300 = 9.00 %\n",
      "Accuracy: 9.00 %\n",
      "--- SUPER EPOCH 6 / 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 1 | Total steps = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.593700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.590200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.480600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.228800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.072700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.719600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,700 | Num Epochs = 1 | Total steps = 27\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 02:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.208649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.210600</td>\n",
       "      <td>0.208091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.203700</td>\n",
       "      <td>0.205885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.202976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.200300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.197545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.194600</td>\n",
       "      <td>0.195678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.194681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.194439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.194293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.193237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.176200</td>\n",
       "      <td>0.191383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.167500</td>\n",
       "      <td>0.189505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.188159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.186818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.187928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.163800</td>\n",
       "      <td>0.191348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.154900</td>\n",
       "      <td>0.194734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>0.194041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.159300</td>\n",
       "      <td>0.193702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.190835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.188937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.187501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.172100</td>\n",
       "      <td>0.190168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.192108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.190087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.174800</td>\n",
       "      <td>0.189250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:24<00:00,  3.55it/s, acc=40.67 %]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final: 122/300 = 40.67 %\n",
      "Accuracy: 40.67 %\n",
      "--- SUPER EPOCH 7 / 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 1 | Total steps = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.062200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.690900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.534900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.370500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,700 | Num Epochs = 1 | Total steps = 27\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 02:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.258200</td>\n",
       "      <td>0.265003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.263400</td>\n",
       "      <td>0.262318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.252100</td>\n",
       "      <td>0.256653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.248134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>0.235111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.218459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.213800</td>\n",
       "      <td>0.199103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>0.182381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.172755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.168893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.149500</td>\n",
       "      <td>0.167226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.166659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>0.166940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>0.167859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.145100</td>\n",
       "      <td>0.167441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>0.167033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>0.165711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>0.166913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.151300</td>\n",
       "      <td>0.166665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.166217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.140400</td>\n",
       "      <td>0.167589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>0.169763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.170312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.168580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.170923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0.174123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.175130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:22<00:00,  3.62it/s, acc=66.67 %]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final: 200/300 = 66.67 %\n",
      "Accuracy: 66.67 %\n",
      "--- SUPER EPOCH 8 / 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 1 | Total steps = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.705900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.720300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.634900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.544700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.318400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.957500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,700 | Num Epochs = 1 | Total steps = 27\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 02:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>0.170154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.157400</td>\n",
       "      <td>0.169216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.156700</td>\n",
       "      <td>0.167744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.165450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>0.162624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.145100</td>\n",
       "      <td>0.160546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.159795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.159989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.144600</td>\n",
       "      <td>0.160841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.161739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.143300</td>\n",
       "      <td>0.161450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.143400</td>\n",
       "      <td>0.160773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.160922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>0.162300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.163012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.163151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.137400</td>\n",
       "      <td>0.163154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.163878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.163882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.164749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.164440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.140900</td>\n",
       "      <td>0.163780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.164372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.165976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>0.166917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.167362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.144300</td>\n",
       "      <td>0.166940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:32<00:00,  3.24it/s, acc=82.00 %]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final: 246/300 = 82.00 %\n",
      "Accuracy: 82.00 %\n",
      "--- SUPER EPOCH 9 / 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 1 | Total steps = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.251300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.256900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.192800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.860100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.642300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,700 | Num Epochs = 1 | Total steps = 27\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 02:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.165824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>0.165271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.164071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.162959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.161030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.159649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.158398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.157365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.157463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.158401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.159490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.141500</td>\n",
       "      <td>0.159995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.160048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.160681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.139700</td>\n",
       "      <td>0.161669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.162788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.162405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.162782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>0.162415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.160888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.160701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.162101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.161733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.162166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.165090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>0.165690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.166751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:24<00:00,  3.56it/s, acc=93.33 %]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final: 280/300 = 93.33 %\n",
      "Accuracy: 93.33 %\n",
      "--- SUPER EPOCH 10 / 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 1 | Total steps = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.848600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.785900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.706100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.590200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.483700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.336600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,700 | Num Epochs = 1 | Total steps = 27\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 02:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.257830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.254716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.252796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.232700</td>\n",
       "      <td>0.245491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>0.233649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.209400</td>\n",
       "      <td>0.218519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.200800</td>\n",
       "      <td>0.200358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.182717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.167625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.159801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>0.155790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.154573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>0.154274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>0.154970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.156094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.130100</td>\n",
       "      <td>0.157676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.159152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.160893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.143600</td>\n",
       "      <td>0.160784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.159662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.159782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.160313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.160678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.139100</td>\n",
       "      <td>0.160899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>0.161923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.166397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.125700</td>\n",
       "      <td>0.169371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:22<00:00,  3.64it/s, acc=94.67 %]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final: 284/300 = 94.67 %\n",
      "Accuracy: 94.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history = []\n",
    "for _ in range(EPOCHS):\n",
    "    print(f\"--- SUPER EPOCH {_+1} / {EPOCHS} ---\")\n",
    "    trainer_sft_stats = trainer_auto.train() \n",
    "    trainer_it_stats = trainer_it.train()\n",
    "    # evaluate accuracy after each super epoch\n",
    "    acc = test_model_accuracy(model, tokenizer, prompts_retrieval_test, device=\"cuda\")\n",
    "    print(f\"Accuracy: {acc:.2f} %\")\n",
    "    history.append({\n",
    "        \"super_epoch\": _ + 1,\n",
    "        \"trainer_sft_stats\": trainer_sft_stats,\n",
    "        \"trainer_it_stats\": trainer_it_stats,\n",
    "        \"accuracy\": acc,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47228fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El nÃºmero 736 615 948 pertenece a Javier MartÃ­n.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# test the model in streaming mode\n",
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=False)\n",
    "_ = model.generate(\n",
    "    **tokenizer(text_for_testing, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 64, # Increase for longer outputs!\n",
    "    do_sample = False,\n",
    "    top_p = 0.1,\n",
    "    temperature = 0.,\n",
    "    streamer = streamer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed78169e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf75a4",
   "metadata": {},
   "source": [
    "### Split training in super epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e74005d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "auto_config = UnslothTrainingArguments(\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 8, # Use GA to mimic batch size!\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=0,\n",
    "    warmup_steps = 5,\n",
    "    num_train_epochs = 10, # Set this for 1 full training run.\n",
    "    #max_steps = 60,\n",
    "    learning_rate = 1e-4, # Reduce to 2e-5 for long training runs\n",
    "    logging_steps = 1,\n",
    "    # 32 bits\n",
    "    optim = \"paged_adamw_32bit\",\n",
    "    weight_decay = 0.01,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    seed = SEED,\n",
    "    report_to = \"none\", # Use this for WandB etc\n",
    "    output_dir=\"../models/qwen3-0.6b-rag-indexer\",\n",
    ")\n",
    "\n",
    "it_config = SFTConfig(\n",
    "    dataset_text_field=\"text\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,        # <-- aÃ±ade eval batch size\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=25,\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=0,\n",
    "    eval_steps=1,\n",
    "    eval_strategy=\"steps\",         # <-- activa evaluaciÃ³n periÃ³dica\n",
    "    num_train_epochs=1,             # <-- opcional: usa epochs en lugar de max_steps\n",
    "    #max_steps=30,\n",
    "    learning_rate=1e-4,\n",
    "    logging_steps=1,\n",
    "    optim = \"paged_adamw_32bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=SEED,\n",
    "    report_to=\"none\",\n",
    "    output_dir=\"../models/qwen3-0.6b-rag-retriever\",\n",
    "    load_best_model_at_end=False,          # <-- opcional\n",
    "    metric_for_best_model=\"eval_loss\",    # <-- opcional\n",
    "    greater_is_better=False,              # <-- opcional\n",
    ")\n",
    "\n",
    "trainer_auto = UnslothTrainer(\n",
    "    model=model,\n",
    "    train_dataset=knowledge_dataset_tokenizer,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    args=auto_config,\n",
    ")\n",
    "\n",
    "trainer_it = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=qa_train_dataset_tokenizer,\n",
    "    eval_dataset=qa_val_dataset_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    args=it_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6cc16e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 400 | Num Epochs = 10 | Total steps = 70\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 02:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.325900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.296200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.141900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.794800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.250100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.886700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.923700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.847300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.863400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.833400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.796700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.746500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.743400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.767700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.724200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.738900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.675700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.689200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.674400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.632900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.636200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.660600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.645800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.653700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.580400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.626300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.553500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.569400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.617600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.555100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.449700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.395400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.386300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.422100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.417600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.188000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.155800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.184600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.173500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.076900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.980100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.978700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.945500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.959700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.937700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.967300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.863800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.850400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.854200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.886900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.850300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.872700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.874700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.823700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.814900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.827400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.818800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.851600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.832300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.820100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,700 | Num Epochs = 1 | Total steps = 27\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 360,710,144 of 1,596,524,544 (22.59% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 02:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.801400</td>\n",
       "      <td>6.797376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.749600</td>\n",
       "      <td>5.844672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.854400</td>\n",
       "      <td>4.569393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.548200</td>\n",
       "      <td>3.430390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.376600</td>\n",
       "      <td>2.751632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.735900</td>\n",
       "      <td>2.153765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.113100</td>\n",
       "      <td>1.609959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.585600</td>\n",
       "      <td>1.227074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.253000</td>\n",
       "      <td>0.953801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.982600</td>\n",
       "      <td>0.879649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.893900</td>\n",
       "      <td>0.699237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.705500</td>\n",
       "      <td>0.611527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.629400</td>\n",
       "      <td>0.539060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.502968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.501500</td>\n",
       "      <td>0.497256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.495400</td>\n",
       "      <td>0.483201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.475900</td>\n",
       "      <td>0.465914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.475300</td>\n",
       "      <td>0.460458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.460500</td>\n",
       "      <td>0.456034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.434600</td>\n",
       "      <td>0.452014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.451300</td>\n",
       "      <td>0.433135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.424600</td>\n",
       "      <td>0.420561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>0.412133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>0.403721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.395700</td>\n",
       "      <td>0.389015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.365645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.371500</td>\n",
       "      <td>0.353105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:25<00:00,  3.49it/s, acc=0.00 %]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final: 0/300 = 0.00 %\n",
      "Accuracy: 0.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer_sft_stats = trainer_auto.train()\n",
    "trainer_it_stats = trainer_it.train()\n",
    "# evaluate accuracy after each super epoch\n",
    "acc = test_model_accuracy(model, tokenizer, prompts_retrieval_test, device=\"cuda\")\n",
    "print(f\"Accuracy: {acc:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f711c62",
   "metadata": {},
   "source": [
    "iterativo(Super epocas = 10) => auto_loss 0.33 || it_loss 0.17 || ACC 0.94\n",
    "\n",
    "NORMAL => auto_loss 0.86 || it_loss 0.35 || ACC 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
