{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "SEED = 123\n",
    "FOLDER = \"../data/processed/legal-qa-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32ba1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the dataset\n",
    "print(dataset)\n",
    "print(dataset['train'][0])\n",
    "print(dataset['validation'][0])\n",
    "print(dataset['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e060b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(example):\n",
    "    # ejemplo: poner preguntas en mayúsculas y respuestas en minúsculas\n",
    "    new_question = example[\"question\"].replace(\"Q:\", \"\").strip()\n",
    "    new_answer = example[\"answer\"].replace(\"A:\", \"\").strip()\n",
    "\n",
    "    return {\n",
    "        \"question\": new_question,\n",
    "        \"answer\": new_answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = dataset.map(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ae487",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformed_dataset[\"question\"][0])\n",
    "print(transformed_dataset[\"answer\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d472793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and validation\n",
    "train_test = transformed_dataset.train_test_split(test_size=0.2, seed=SEED)\n",
    "print(train_test)\n",
    "train_val = train_test[\"test\"].train_test_split(test_size=0.5, seed=SEED)\n",
    "transformed_dataset = {\n",
    "    \"train\": train_test[\"train\"],\n",
    "    \"val\": train_val[\"test\"],\n",
    "    \"test\": train_val[\"train\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef6830f",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e462fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class SentenceTransformerEmbeddings(Embeddings):\n",
    "\n",
    "    def __init__(self, model: str, device: str = 'cuda'):\n",
    "        self.model = SentenceTransformer(model, device=device)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Embed search docs.\"\"\"\n",
    "        return self.model.encode(texts).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Embed query text.\"\"\"\n",
    "        return self.model.encode_query(text).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d99403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "model = SentenceTransformerEmbeddings(model=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "loaded_vectorstore=FAISS.load_local(\n",
    "    \"../data/db/parliament_db/parliament_all_docs_embeddings_sentence-transformers_paraphrase-multilingual-mpnet-base-v2\",\n",
    "    model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "print(f\"Loaded vector store contains {loaded_vectorstore.index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719abab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all embeddings in numpy array\n",
    "import numpy as np\n",
    "all_embeddings = np.array([emb for emb in loaded_vectorstore.index.reconstruct_n(0, loaded_vectorstore.index.ntotal)])\n",
    "print(f\"All embeddings shape: {all_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of the embeddings cosine similarity distribution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarities = cosine_similarity(all_embeddings)\n",
    "# get the upper triangle of the cosine similarities matrix, without the diagonal\n",
    "upper_triangle_indices = np.triu_indices_from(cosine_similarities, k=1)\n",
    "upper_triangle_values = cosine_similarities[upper_triangle_indices]\n",
    "\n",
    "plt.hist(upper_triangle_values, bins=50)\n",
    "plt.grid()\n",
    "plt.title(\"Cosine Similarity Distribution of Embeddings\")\n",
    "plt.xlabel(\"Cosine Similarity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e48a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the mean and standard deviation of the cosine similarities\n",
    "mean_cosine_similarity = np.mean(upper_triangle_values)\n",
    "std_cosine_similarity = np.std(upper_triangle_values)\n",
    "# print the results rounded to 4 decimal places\n",
    "print(f\"Mean Cosine Similarity: {mean_cosine_similarity:.4f}\")\n",
    "print(f\"Standard Deviation of Cosine Similarity: {std_cosine_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load train/validation/test splits of individual subset\n",
    "ragbench_hotpotqa = load_dataset(\"rungalileo/ragbench\", \"hotpotqa\")\n",
    "print(ragbench_hotpotqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e65861",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragbench = {}\n",
    "for dataset in ['covidqa', 'cuad', 'delucionqa', 'emanual', 'expertqa', 'finqa', 'hagrid', 'hotpotqa', 'msmarco', 'pubmedqa', 'tatqa', 'techqa']:\n",
    "  ragbench[dataset] = load_dataset(\"rungalileo/ragbench\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragbench[\"covidqa\"][\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## quiero solo estas columnas\n",
    "columns_to_keep = [\"id\", \"question\", \"documents\", \"response\"]\n",
    "for subset in ragbench:\n",
    "    ragbench[subset] = ragbench[subset].remove_columns([col for col in ragbench[subset]['train'].column_names if col not in columns_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = []\n",
    "for split in ragbench[\"covidqa\"]:\n",
    "    for docs in ragbench[\"covidqa\"][split][\"documents\"]:\n",
    "        for doc in docs:\n",
    "            document.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique documents in alphabetical order\n",
    "len(set(document))\n",
    "unique_documents = list(set(document))\n",
    "unique_documents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734422a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with the idx of the document in the list of unique documents, the idx should be a list of integers and the name of the column should be \"document_ids\"\n",
    "unique_documents = list(set(document))\n",
    "unique_documents.sort()\n",
    "document_idx_map = {doc: idx for idx, doc in enumerate(unique_documents)}\n",
    "for split in ragbench[\"covidqa\"]:\n",
    "    ragbench[\"covidqa\"][split] = ragbench[\"covidqa\"][split].add_column(\n",
    "        \"document_ids\",\n",
    "        [[document_idx_map[doc] for doc in docs] for docs in ragbench[\"covidqa\"][split][\"documents\"]]\n",
    "    )\n",
    "ragbench[\"covidqa\"][\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk the list of unique documents in jsonl format\n",
    "import os\n",
    "import json\n",
    "\n",
    "with open(\"../data/processed/ragbench/covidqa_unique_documents.jsonl\", \"w\") as f:\n",
    "    for doc in unique_documents:\n",
    "        f.write(json.dumps({\"document\": doc}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a821a1",
   "metadata": {},
   "source": [
    "# Parliamentary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae110394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "FOLDER_AUTORE = \"../data/raw/ORDERS_PARLIAMENT\" # Entrenamiento autoregresivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ba703",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_aut = load_from_disk(FOLDER_AUTORE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b423a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_aut[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5eba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_aut['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c347b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "FOLDER_QA = \"../data/raw/QA_PARLIAMENT_TRAIN\"\n",
    "\n",
    "dataset_qa = load_from_disk(FOLDER_QA)\n",
    "print(dataset_qa)\n",
    "print(dataset_qa[\"train\"])\n",
    "print(json.dumps(dataset_qa['train'][3], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18614b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dataset_qa[\"train\"][10][\"context\"]\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3734167",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.replace(\"[Documento]:\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d696e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "FOLDER_QA = \"../data/raw/QA_PARLIAMENT_TEST\"\n",
    "\n",
    "dataset_qa = load_from_disk(FOLDER_QA)\n",
    "print(dataset_qa[\"test\"])\n",
    "print(json.dumps(dataset_qa['test'][3], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb42da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dataset_qa[\"test\"][3][\"formatted_context\"]\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac73a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pks = dataset_qa[\"test\"][:]['PK']\n",
    "print(pks)\n",
    "# hay algunos pk vacíos?\n",
    "pks.count(\"\")\n",
    "\n",
    "pk_1 = pks[1]\n",
    "\n",
    "# buscar en dataset_aut \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d45bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"../data/processed/parliament_all_docs\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737655ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
