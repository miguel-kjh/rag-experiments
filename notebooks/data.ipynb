{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81f2475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "SEED = 123\n",
    "FOLDER = \"../data/processed/squad_qa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73cb68dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_from_disk(FOLDER)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32ba1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the dataset\n",
    "print(dataset)\n",
    "print(dataset['train'][0])\n",
    "print(dataset['validation'][0])\n",
    "print(dataset['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e060b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(example):\n",
    "    # ejemplo: poner preguntas en mayúsculas y respuestas en minúsculas\n",
    "    new_question = example[\"question\"].replace(\"Q:\", \"\").strip()\n",
    "    new_answer = example[\"answer\"].replace(\"A:\", \"\").strip()\n",
    "\n",
    "    return {\n",
    "        \"question\": new_question,\n",
    "        \"answer\": new_answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = dataset.map(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ae487",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformed_dataset[\"question\"][0])\n",
    "print(transformed_dataset[\"answer\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d472793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and validation\n",
    "train_test = transformed_dataset.train_test_split(test_size=0.2, seed=SEED)\n",
    "print(train_test)\n",
    "train_val = train_test[\"test\"].train_test_split(test_size=0.5, seed=SEED)\n",
    "transformed_dataset = {\n",
    "    \"train\": train_test[\"train\"],\n",
    "    \"val\": train_val[\"test\"],\n",
    "    \"test\": train_val[\"train\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef6830f",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e462fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class SentenceTransformerEmbeddings(Embeddings):\n",
    "\n",
    "    def __init__(self, model: str, device: str = 'cuda'):\n",
    "        self.model = SentenceTransformer(model, device=device)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Embed search docs.\"\"\"\n",
    "        return self.model.encode(texts).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Embed query text.\"\"\"\n",
    "        return self.model.encode_query(text).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d99403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vector store contains 128518 vectors\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model = HuggingFaceEmbeddings(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-0.6B\",\n",
    "    model_kwargs={\"device\": \"cuda\"}\n",
    ")\n",
    "\n",
    "loaded_vectorstore=FAISS.load_local(\n",
    "    \"../data/db/parliament_db/parliament_all_docs_embeddings_Qwen_Qwen3-Embedding-0.6B_chunked_max_length-512\",\n",
    "    model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "print(f\"Loaded vector store contains {loaded_vectorstore.index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719abab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All embeddings shape: (128518, 1024)\n"
     ]
    }
   ],
   "source": [
    "# get all embeddings in numpy array\n",
    "import numpy as np\n",
    "all_embeddings = np.array([emb for emb in loaded_vectorstore.index.reconstruct_n(0, loaded_vectorstore.index.ntotal)])\n",
    "print(f\"All embeddings shape: {all_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820e759",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 61.5 GiB for an array with shape (128518, 128518) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m----> 6\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# get the upper triangle of the cosine similarities matrix, without the diagonal\u001b[39;00m\n\u001b[1;32m      8\u001b[0m upper_triangle_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtriu_indices_from(cosine_similarities, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1687\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1687\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/extmath.py:205\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    203\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    208\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    212\u001b[0m ):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 61.5 GiB for an array with shape (128518, 128518) and data type float32"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# plot histogram of the embeddings cosine similarity distribution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarities = cosine_similarity(all_embeddings)\n",
    "# get the upper triangle of the cosine similarities matrix, without the diagonal\n",
    "upper_triangle_indices = np.triu_indices_from(cosine_similarities, k=1)\n",
    "upper_triangle_values = cosine_similarities[upper_triangle_indices]\n",
    "\n",
    "plt.hist(upper_triangle_values, bins=50)\n",
    "plt.grid()\n",
    "plt.title(\"Cosine Similarity Distribution of Embeddings\")\n",
    "plt.xlabel(\"Cosine Similarity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54e48a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cosine Similarity: 0.7246\n",
      "Standard Deviation of Cosine Similarity: 0.1009\n"
     ]
    }
   ],
   "source": [
    "# print the mean and standard deviation of the cosine similarities\n",
    "mean_cosine_similarity = np.mean(upper_triangle_values)\n",
    "std_cosine_similarity = np.std(upper_triangle_values)\n",
    "# print the results rounded to 4 decimal places\n",
    "print(f\"Mean Cosine Similarity: {mean_cosine_similarity:.4f}\")\n",
    "print(f\"Standard Deviation of Cosine Similarity: {std_cosine_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load train/validation/test splits of individual subset\n",
    "ragbench_hotpotqa = load_dataset(\"rungalileo/ragbench\", \"hotpotqa\")\n",
    "print(ragbench_hotpotqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e65861",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragbench = {}\n",
    "for dataset in ['covidqa', 'cuad', 'delucionqa', 'emanual', 'expertqa', 'finqa', 'hagrid', 'hotpotqa', 'msmarco', 'pubmedqa', 'tatqa', 'techqa']:\n",
    "  ragbench[dataset] = load_dataset(\"rungalileo/ragbench\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragbench[\"covidqa\"][\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## quiero solo estas columnas\n",
    "columns_to_keep = [\"id\", \"question\", \"documents\", \"response\"]\n",
    "for subset in ragbench:\n",
    "    ragbench[subset] = ragbench[subset].remove_columns([col for col in ragbench[subset]['train'].column_names if col not in columns_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = []\n",
    "for split in ragbench[\"covidqa\"]:\n",
    "    for docs in ragbench[\"covidqa\"][split][\"documents\"]:\n",
    "        for doc in docs:\n",
    "            document.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique documents in alphabetical order\n",
    "len(set(document))\n",
    "unique_documents = list(set(document))\n",
    "unique_documents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734422a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with the idx of the document in the list of unique documents, the idx should be a list of integers and the name of the column should be \"document_ids\"\n",
    "unique_documents = list(set(document))\n",
    "unique_documents.sort()\n",
    "document_idx_map = {doc: idx for idx, doc in enumerate(unique_documents)}\n",
    "for split in ragbench[\"covidqa\"]:\n",
    "    ragbench[\"covidqa\"][split] = ragbench[\"covidqa\"][split].add_column(\n",
    "        \"document_ids\",\n",
    "        [[document_idx_map[doc] for doc in docs] for docs in ragbench[\"covidqa\"][split][\"documents\"]]\n",
    "    )\n",
    "ragbench[\"covidqa\"][\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk the list of unique documents in jsonl format\n",
    "import os\n",
    "import json\n",
    "\n",
    "with open(\"../data/processed/ragbench/covidqa_unique_documents.jsonl\", \"w\") as f:\n",
    "    for doc in unique_documents:\n",
    "        f.write(json.dumps({\"document\": doc}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a821a1",
   "metadata": {},
   "source": [
    "# Parliamentary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae110394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "FOLDER_AUTORE = \"../data/raw/ORDERS_PARLIAMENT\" # Entrenamiento autoregresivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ba703",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_aut = load_from_disk(FOLDER_AUTORE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b423a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_aut[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5eba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_aut['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c347b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['PK', 'question', 'answer', 'cost', 'context', 'type', 'retrieved_pks', 'oracle_context', 'formatted_context'],\n",
      "        num_rows: 614\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['PK', 'question', 'answer', 'cost', 'context', 'type', 'retrieved_pks', 'oracle_context', 'formatted_context'],\n",
      "        num_rows: 161\n",
      "    })\n",
      "})\n",
      "Dataset({\n",
      "    features: ['PK', 'question', 'answer', 'cost', 'context', 'type', 'retrieved_pks', 'oracle_context', 'formatted_context'],\n",
      "    num_rows: 614\n",
      "})\n",
      "{\n",
      "  \"PK\": \"6521_1\",\n",
      "  \"question\": \"\\u00bfQu\\u00e9 argumentos expuso el grupo parlamentario que se opuso a la propuesta de modificaci\\u00f3n del orden del d\\u00eda en la sesi\\u00f3n del 26 de septiembre de 2023, que implicaba la convalidaci\\u00f3n del decreto relativo al impuesto de sucesiones y donaciones?\",\n",
      "  \"answer\": \"El fragmento del Diario de Sesiones no proporciona argumentos espec\\u00edficos de ning\\u00fan grupo parlamentario que se oponga a la propuesta de modificaci\\u00f3n del orden del d\\u00eda relacionada con la convalidaci\\u00f3n del decreto sobre el impuesto de sucesiones y donaciones. La presidenta menciona que se somete la propuesta a votaci\\u00f3n por asentimiento y no se registran objeciones ni intervenciones en contra. Por lo tanto, no se pueden extraer argumentos de oposici\\u00f3n de los grupos parlamentarios en este caso.\",\n",
      "  \"cost\": 0.00011774999999999999,\n",
      "  \"context\": \"Esta sesi\\u00f3n del parlamento se realiz\\u00f3 el 2023-09-26. PROPUESTA DE ALTERACI\\u00d3N DEL ORDEN DEL D\\u00cdA La se\\u00f1ora PRESIDENTA: Como cuesti\\u00f3n previa s\\u00ed nos gustar\\u00eda plantear una propuesta de modificaci\\u00f3n del orden del d\\u00eda, que, como bien saben, debo someterla a votaci\\u00f3n por asentimiento. Por tanto, simplemente que los grupos, los portavoces de los grupos parlamentarios asientan sobre esta propuesta de modificaci\\u00f3n del orden del d\\u00eda. \\u00bfAlguna cuesti\\u00f3n en contra de la propuesta de modificaci\\u00f3n? Como bien saben, se trataba de modificar y sustituir el decreto, la convalidaci\\u00f3n del decreto relativo al impuesto de sucesiones y donaciones, poder debatirlo despu\\u00e9s de las preguntas y antes de las comparecencias. Esa es la modificaci\\u00f3n del orden del d\\u00eda que les planteo, y, por tanto, por asentimiento imagino que no habr\\u00e1 ning\\u00fan problema, \\u00bfverdad? (Asentimiento). Bueno, pues no habiendo nada que alegar, pasamos al orden del d\\u00eda.\",\n",
      "  \"type\": \"motivation\",\n",
      "  \"retrieved_pks\": [\n",
      "    \"6521_1\",\n",
      "    \"6521_27\",\n",
      "    \"6516_15\",\n",
      "    \"6123_19\",\n",
      "    \"6553_8\",\n",
      "    \"6593_11\",\n",
      "    \"6598_19\"\n",
      "  ],\n",
      "  \"oracle_context\": true,\n",
      "  \"formatted_context\": \"[Documento]:\\n\\nEsta sesi\\u00f3n del parlamento se realiz\\u00f3 el 2023-09-26. PROPUESTA DE ALTERACI\\u00d3N DEL ORDEN DEL D\\u00cdA La se\\u00f1ora PRESIDENTA: Como cuesti\\u00f3n previa s\\u00ed nos gustar\\u00eda plantear una propuesta de modificaci\\u00f3n del orden del d\\u00eda, que, como bien saben, debo someterla a votaci\\u00f3n por asentimiento. Por tanto, simplemente que los grupos, los portavoces de los grupos parlamentarios asientan sobre esta propuesta de modificaci\\u00f3n del orden del d\\u00eda. \\u00bfAlguna cuesti\\u00f3n en contra de la propuesta de modificaci\\u00f3n? Como bien saben, se trataba de modificar y sustituir el decreto, la convalidaci\\u00f3n del decreto relativo al impuesto de sucesiones y donaciones, poder debatirlo despu\\u00e9s de las preguntas y antes de las comparecencias. Esa es la modificaci\\u00f3n del orden del d\\u00eda que les planteo, y, por tanto, por asentimiento imagino que no habr\\u00e1 ning\\u00fan problema, \\u00bfverdad? (Asentimiento). Bueno, pues no habiendo nada que alegar, pasamos al orden del d\\u00eda.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "FOLDER_QA = \"../data/raw/QA_PARLIAMENT_TRAIN\"\n",
    "\n",
    "dataset_qa = load_from_disk(FOLDER_QA)\n",
    "print(dataset_qa)\n",
    "print(dataset_qa[\"train\"])\n",
    "print(json.dumps(dataset_qa['train'][3], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18614b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dataset_qa[\"train\"][10][\"context\"]\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3734167",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.replace(\"[Documento]:\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d696e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "FOLDER_QA = \"../data/raw/QA_PARLIAMENT_TEST\"\n",
    "\n",
    "dataset_qa = load_from_disk(FOLDER_QA)\n",
    "print(dataset_qa[\"test\"])\n",
    "print(json.dumps(dataset_qa['test'][3], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb42da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dataset_qa[\"test\"][3][\"formatted_context\"]\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac73a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pks = dataset_qa[\"test\"][:]['PK']\n",
    "print(pks)\n",
    "# hay algunos pk vacíos?\n",
    "pks.count(\"\")\n",
    "\n",
    "pk_1 = pks[1]\n",
    "\n",
    "# buscar en dataset_aut \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d45bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"../data/processed/parliament_all_docs\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737655ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4a57e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 87599\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 10570\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rajpurkar/squad\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19931730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use other dataset for title and context columns\n",
    "dataset_knowledge_columns = [\"title\", \"context\"]\n",
    "title = dataset[\"train\"][\"title\"][:]\n",
    "title += dataset[\"validation\"][\"title\"][:]\n",
    "context = dataset[\"train\"][\"context\"][:]\n",
    "context += dataset[\"validation\"][\"context\"][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af27678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_knowledge = {\n",
    "    \"title\": [],\n",
    "    \"text\": []\n",
    "}\n",
    "for t, c in zip(title, context):\n",
    "    dataset_knowledge[\"title\"].append(t)\n",
    "    dataset_knowledge[\"text\"].append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98fd5c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset_knowledge = Dataset.from_dict(dataset_knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab51daae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 98169/98169 [00:00<00:00, 489292.77 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['title', 'text'],\n",
      "    num_rows: 20958\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_texts = set()\n",
    "def is_unique(example):\n",
    "    if example[\"text\"] in unique_texts:\n",
    "        return False\n",
    "    unique_texts.add(example[\"text\"])\n",
    "    return True\n",
    "dataset_unique = dataset_knowledge.filter(is_unique)\n",
    "print(dataset_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7739c8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 98169 muestras\n",
      "Únicas: 20958 muestras\n",
      "{'title': ['University_of_Notre_Dame', 'University_of_Notre_Dame', 'University_of_Notre_Dame'], 'text': ['Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', \"As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary's College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut.\", 'The university is the major seat of the Congregation of Holy Cross (albeit not its official headquarters, which are in Rome). Its main seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the Grotto. The university through the Moreau Seminary has ties to theologian Frederick Buechner. While not Catholic, Buechner has praised writers from Notre Dame and Moreau Seminary created a Buechner Prize for Preaching.']}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original: {len(dataset_knowledge)} muestras\")\n",
    "print(f\"Únicas: {len(dataset_unique)} muestras\")\n",
    "\n",
    "# Ver las primeras filas\n",
    "print(dataset_unique[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
