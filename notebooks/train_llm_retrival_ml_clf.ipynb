{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02911839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse, os, numpy as np, torch\n",
    "from datasets import load_dataset, ClassLabel\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from transformers import BitsAndBytesConfig\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee5bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 400/400 [00:00<00:00, 34054.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 400\n",
      "Labels: ['7500_1', '7500_2', '7500_3', '7500_4', '7500_5', '7501_1', '7501_2', '7501_3', '7501_4', '7501_5', '7502_1', '7502_2', '7502_3', '7502_4', '7502_5', '7503_1', '7503_2', '7503_3', '7503_4', '7503_5', '7504_1', '7504_2', '7504_3', '7504_4', '7504_5', '7505_1', '7505_2', '7505_3', '7505_4', '7505_5', '7506_1', '7506_2', '7506_3', '7506_4', '7506_5', '7507_1', '7507_2', '7507_3', '7507_4', '7507_5', '7508_1', '7508_2', '7508_3', '7508_4', '7508_5', '7509_1', '7509_2', '7509_3', '7509_4', '7509_5', '7510_1', '7510_2', '7510_3', '7510_4', '7510_5', '7511_1', '7511_2', '7511_3', '7511_4', '7511_5', '7512_1', '7512_2', '7512_3', '7512_4', '7512_5', '7513_1', '7513_2', '7513_3', '7513_4', '7513_5', '7514_1', '7514_2', '7514_3', '7514_4', '7514_5', '7515_1', '7515_2', '7515_3', '7515_4', '7515_5', '7516_1', '7516_2', '7516_3', '7516_4', '7516_5', '7517_1', '7517_2', '7517_3', '7517_4', '7517_5', '7518_1', '7518_2', '7518_3', '7518_4', '7518_5', '7519_1', '7519_2', '7519_3', '7519_4', '7519_5', '7520_1', '7520_2', '7520_3', '7520_4', '7520_5', '7521_1', '7521_2', '7521_3', '7521_4', '7521_5', '7522_1', '7522_2', '7522_3', '7522_4', '7522_5', '7523_1', '7523_2', '7523_3', '7523_4', '7523_5', '7524_1', '7524_2', '7524_3', '7524_4', '7524_5', '7525_1', '7525_2', '7525_3', '7525_4', '7525_5', '7526_1', '7526_2', '7526_3', '7526_4', '7526_5', '7527_1', '7527_2', '7527_3', '7527_4', '7527_5', '7528_1', '7528_2', '7528_3', '7528_4', '7528_5', '7529_1', '7529_2', '7529_3', '7529_4', '7529_5', '7530_1', '7530_2', '7530_3', '7530_4', '7530_5', '7531_1', '7531_2', '7531_3', '7531_4', '7531_5', '7532_1', '7532_2', '7532_3', '7532_4', '7532_5', '7533_1', '7533_2', '7533_3', '7533_4', '7533_5', '7534_1', '7534_2', '7534_3', '7534_4', '7534_5', '7535_1', '7535_2', '7535_3', '7535_4', '7535_5', '7536_1', '7536_2', '7536_3', '7536_4', '7536_5', '7537_1', '7537_2', '7537_3', '7537_4', '7537_5', '7538_1', '7538_2', '7538_3', '7538_4', '7538_5', '7539_1', '7539_2', '7539_3', '7539_4', '7539_5', '7540_1', '7540_2', '7540_3', '7540_4', '7540_5', '7541_1', '7541_2', '7541_3', '7541_4', '7541_5', '7542_1', '7542_2', '7542_3', '7542_4', '7542_5', '7543_1', '7543_2', '7543_3', '7543_4', '7543_5', '7544_1', '7544_2', '7544_3', '7544_4', '7544_5', '7545_1', '7545_2', '7545_3', '7545_4', '7545_5', '7546_1', '7546_2', '7546_3', '7546_4', '7546_5', '7547_1', '7547_2', '7547_3', '7547_4', '7547_5', '7548_1', '7548_2', '7548_3', '7548_4', '7548_5', '7549_1', '7549_2', '7549_3', '7549_4', '7549_5', '7550_1', '7550_2', '7550_3', '7550_4', '7550_5', '7551_1', '7551_2', '7551_3', '7551_4', '7551_5', '7552_1', '7552_2', '7552_3', '7552_4', '7552_5', '7553_1', '7553_2', '7553_3', '7553_4', '7553_5', '7554_1', '7554_2', '7554_3', '7554_4', '7554_5', '7555_1', '7555_2', '7555_3', '7555_4', '7555_5', '7556_1', '7556_2', '7556_3', '7556_4', '7556_5', '7557_1', '7557_2', '7557_3', '7557_4', '7557_5', '7558_1', '7558_2', '7558_3', '7558_4', '7558_5', '7559_1', '7559_2', '7559_3', '7559_4', '7559_5', '7560_1', '7560_2', '7560_3', '7560_4', '7560_5', '7561_1', '7561_2', '7561_3', '7561_4', '7561_5', '7562_1', '7562_2', '7562_3', '7562_4', '7562_5', '7563_1', '7563_2', '7563_3', '7563_4', '7563_5', '7564_1', '7564_2', '7564_3', '7564_4', '7564_5', '7565_1', '7565_2', '7565_3', '7565_4', '7565_5', '7566_1', '7566_2', '7566_3', '7566_4', '7566_5', '7567_1', '7567_2', '7567_3', '7567_4', '7567_5', '7568_1', '7568_2', '7568_3', '7568_4', '7568_5', '7569_1', '7569_2', '7569_3', '7569_4', '7569_5', '7570_1', '7570_2', '7570_3', '7570_4', '7570_5', '7571_1', '7571_2', '7571_3', '7571_4', '7571_5', '7572_1', '7572_2', '7572_3', '7572_4', '7572_5', '7573_1', '7573_2', '7573_3', '7573_4', '7573_5', '7574_1', '7574_2', '7574_3', '7574_4', '7574_5', '7575_1', '7575_2', '7575_3', '7575_4', '7575_5', '7576_1', '7576_2', '7576_3', '7576_4', '7576_5', '7577_1', '7577_2', '7577_3', '7577_4', '7577_5', '7578_1', '7578_2', '7578_3', '7578_4', '7578_5', '7579_1', '7579_2', '7579_3', '7579_4', '7579_5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 400/400 [00:00<00:00, 48209.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_indexing_csv = pd.read_csv(\"../notebooks/data/contacts_docs.csv\")\n",
    "\n",
    "# to dataset huggingface\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset_indexing = Dataset.from_pandas(dataset_indexing_csv)\n",
    "\n",
    "# create a new column 'text' that concatenates 'name', 'phone'\n",
    "def concatenate_columns(example):\n",
    "    return {\n",
    "        \"text\": f\"Nombre: {example['name']}\\nTeléfono: {example['phone']}\"\n",
    "    }\n",
    "dataset_indexing = dataset_indexing.map(concatenate_columns)\n",
    "# rename column 'id' to 'label'\n",
    "dataset_indexing = dataset_indexing.rename_column(\"id\", \"label\")\n",
    "\n",
    "num_labels = len(dataset_indexing['label'])\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "labels_list = dataset_indexing.unique('label')\n",
    "print(f\"Labels: {labels_list}\")\n",
    "\n",
    "# map labels to integers\n",
    "label_to_id = {label: i for i, label in enumerate(labels_list)}\n",
    "def map_labels(example):\n",
    "    return {\n",
    "        \"label\": label_to_id[example['label']]\n",
    "    }\n",
    "dataset_indexing = dataset_indexing.map(map_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df77002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dataset_train = pd.read_csv(\"../notebooks/data/contacts_queries_train.csv\")\n",
    "query_dataset_val = pd.read_csv(\"../notebooks/data/contacts_queries_val.csv\")\n",
    "query_dataset_test = pd.read_csv(\"../notebooks/data/contacts_queries_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88962b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1400/1400 [00:00<00:00, 53955.45 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 55827.29 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 32043.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '¿Cómo puedo contactar con Antonio Alonso?', 'label': 194}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_for_queries = {\n",
    "    \"train\": Dataset.from_pandas(query_dataset_train),\n",
    "    \"validation\": Dataset.from_pandas(query_dataset_val),\n",
    "    \"test\": Dataset.from_pandas(query_dataset_test)\n",
    "}\n",
    "\n",
    "for split in dataset_for_queries:\n",
    "    dataset_for_queries[split] = dataset_for_queries[split].rename_column(\"question\", \"text\")\n",
    "    dataset_for_queries[split] = dataset_for_queries[split].rename_column(\"id\", \"label\")\n",
    "    # map labels to integers\n",
    "    dataset_for_queries[split] = dataset_for_queries[split].map(map_labels)\n",
    "\n",
    "# to dataset huggingface\n",
    "from datasets import DatasetDict\n",
    "dataset_for_queries = DatasetDict(dataset_for_queries)\n",
    "print(dataset_for_queries[\"train\"][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136616c",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c076355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents created for indexing: 400\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.retrievers import BM25Retriever\n",
    "\n",
    "def create_documents_from_datasets(datasets):\n",
    "    documents = []\n",
    "    for dataset in datasets:\n",
    "        for item in dataset:\n",
    "            doc = Document(\n",
    "                page_content=item[\"text\"],\n",
    "                metadata={\"label\": item[\"label\"]}\n",
    "            )\n",
    "            documents.append(doc)\n",
    "    return documents\n",
    "documents_indexing = create_documents_from_datasets([dataset_indexing])\n",
    "print(f\"Number of documents created for indexing: {len(documents_indexing)}\")\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-0.6B\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents_indexing, embedding_model)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 100})\n",
    "\n",
    "retriever_sparse = BM25Retriever.from_documents(documents_indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80e801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]/tmp/ipykernel_701026/1615760136.py:13: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(query)\n",
      "100%|██████████| 300/300 [00:08<00:00, 35.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "list_of_labels_embeddings = []\n",
    "list_of_labels_sparse = []\n",
    "list_of_real_labels_embeddings = []\n",
    "for index in tqdm(range(len(dataset_for_queries[\"test\"]))):\n",
    "    query = dataset_for_queries[\"test\"][index][\"text\"]\n",
    "    real_label_id = dataset_for_queries[\"test\"][index][\"label\"]\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "    real_label = id_to_label[real_label_id]\n",
    "\n",
    "    # retrieve documents\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    # get labels from retrieved documents\n",
    "    retrieved_labels = [doc.metadata[\"label\"] for doc in docs]\n",
    "    # to names\n",
    "    retrieved_labels = [id_to_label[label_id] for label_id in retrieved_labels]\n",
    "    list_of_labels_embeddings.append(retrieved_labels)\n",
    "    list_of_real_labels_embeddings.append([real_label])\n",
    "\n",
    "    # retrieve documents (sparse)\n",
    "    docs_sparse = retriever_sparse.get_relevant_documents(query)\n",
    "    # get labels from retrieved documents\n",
    "    retrieved_labels_sparse = [doc.metadata[\"label\"] for doc in docs_sparse]\n",
    "    # to names\n",
    "    retrieved_labels_sparse = [id_to_label[label_id] for label_id in retrieved_labels_sparse]\n",
    "    list_of_labels_sparse.append(retrieved_labels_sparse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8dd8d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking Metrics:\n",
      "  MRR: 0.7261\n",
      "  mAP: 0.7261\n",
      "  AvgRank: 7.6983\n",
      "  CMC@1: 0.6800\n",
      "  Recall@k (macro)@1: 0.6800\n",
      "  Precision@k (macro)@1: 0.6800\n",
      "  Accuracy@1: 0.6800\n",
      "  F1@k (macro)@1: 0.6800\n",
      "  CMC@5: 0.7600\n",
      "  Recall@k (macro)@5: 0.7600\n",
      "  Precision@k (macro)@5: 0.1520\n",
      "  Accuracy@5: 0.7600\n",
      "  F1@k (macro)@5: 0.2533\n",
      "  CMC@10: 0.8300\n",
      "  Recall@k (macro)@10: 0.8300\n",
      "  Precision@k (macro)@10: 0.0830\n",
      "  Accuracy@10: 0.8300\n",
      "  F1@k (macro)@10: 0.1509\n",
      "  CMC@20: 0.8833\n",
      "  Recall@k (macro)@20: 0.8833\n",
      "  Precision@k (macro)@20: 0.0442\n",
      "  Accuracy@20: 0.8833\n",
      "  F1@k (macro)@20: 0.0841\n",
      "  CMC@100: 0.9833\n",
      "  Recall@k (macro)@100: 0.9833\n",
      "  Precision@k (macro)@100: 0.0098\n",
      "  Accuracy@100: 0.9833\n",
      "  F1@k (macro)@100: 0.0195\n"
     ]
    }
   ],
   "source": [
    "from ranking_metrics import calc_ranking_metrics\n",
    "\n",
    "metrics = calc_ranking_metrics(list_of_labels_embeddings, list_of_real_labels_embeddings, ks=[1, 5, 10, 20, 100], one_relevant_per_query=True)\n",
    "\n",
    "print(\"Ranking Metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4709eca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Ranking Metrics:\n",
      "  MRR: 0.5539\n",
      "  mAP: 0.5539\n",
      "  AvgRank: 1.4158\n",
      "  CMC@1: 0.5133\n",
      "  Recall@k (macro)@1: 0.5133\n",
      "  Precision@k (macro)@1: 0.5133\n",
      "  Accuracy@1: 0.5133\n",
      "  F1@k (macro)@1: 0.5133\n",
      "  CMC@5: 0.6333\n",
      "  Recall@k (macro)@5: 0.6333\n",
      "  Precision@k (macro)@5: 0.1267\n",
      "  Accuracy@5: 0.6333\n",
      "  F1@k (macro)@5: 0.2111\n",
      "  CMC@10: 0.6333\n",
      "  Recall@k (macro)@10: 0.6333\n",
      "  Precision@k (macro)@10: 0.0633\n",
      "  Accuracy@10: 0.6333\n",
      "  F1@k (macro)@10: 0.1152\n",
      "  CMC@20: 0.6333\n",
      "  Recall@k (macro)@20: 0.6333\n",
      "  Precision@k (macro)@20: 0.0317\n",
      "  Accuracy@20: 0.6333\n",
      "  F1@k (macro)@20: 0.0603\n",
      "  CMC@100: 0.6333\n",
      "  Recall@k (macro)@100: 0.6333\n",
      "  Precision@k (macro)@100: 0.0063\n",
      "  Accuracy@100: 0.6333\n",
      "  F1@k (macro)@100: 0.0125\n"
     ]
    }
   ],
   "source": [
    "metrics_sparse = calc_ranking_metrics(list_of_labels_sparse, list_of_real_labels_embeddings, ks=[1, 5, 10, 20, 100], one_relevant_per_query=True)\n",
    "\n",
    "print(\"Sparse Ranking Metrics:\")\n",
    "for k, v in metrics_sparse.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1107a838",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19767e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4f1a9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-0.6B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b372807",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_r = 256\n",
    "lora_alpha = lora_r * 2\n",
    "lora_dropout = 0.0\n",
    "lora_bias = \"none\"\n",
    "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"up_proj\", \"down_proj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f23ba430",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    inference_mode=False,\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=lora_bias,\n",
    "    target_modules=target_modules\n",
    ")\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c43bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.base_model.model.score.parameters():\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "579c201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 400/400 [00:00<00:00, 36311.96 examples/s]\n",
      "Map: 100%|██████████| 1400/1400 [00:00<00:00, 87684.05 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 50442.62 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 48046.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=MAX_LENGTH, padding=False)\n",
    "\n",
    "# tokenize test from dataset\n",
    "tokenized_datasets_indexing = dataset_indexing.map(preprocess, batched=True)\n",
    "tokenized_datasets_query = dataset_for_queries.map(preprocess, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c2db441",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=8)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = (preds == labels).mean()\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3585bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "SEED = 42\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "training_args_indexing = TrainingArguments(\n",
    "    output_dir=f\"models/contacts_clf_{model_name.replace('/', '_')}_indexing\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"steps\",     # o \"no\" si no vas a evaluar\n",
    "    save_strategy=\"no\",        # <-- no guarda checkpoints ni el modelo final\n",
    "    eval_steps=10,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=False,  # <-- desactivado porque no hay checkpoints\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "training_args_query = TrainingArguments(\n",
    "    output_dir=f\"models/contacts_clf_{model_name.replace('/', '_')}_query\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"no\",        # <-- no guarda checkpoints ni el modelo final\n",
    "    eval_steps=10,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=False,  # <-- desactivado porque no hay checkpoints\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# IDs de tokens\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.bos_token_id = tokenizer.bos_token_id\n",
    "\n",
    "trainer_indexing = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_indexing,\n",
    "    train_dataset=tokenized_datasets_indexing,\n",
    "    eval_dataset=tokenized_datasets_query[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_query = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_query,\n",
    "    train_dataset=tokenized_datasets_query[\"train\"],\n",
    "    eval_dataset=tokenized_datasets_query[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bc5c22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 132,939,776 || all params: 728,989,696 || trainable%: 18.2362\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()  # Verificar parámetros entrenables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "044ea9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########Starting training cycle 1##########\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 00:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.415300</td>\n",
       "      <td>7.407220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.265100</td>\n",
       "      <td>6.572969</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.147600</td>\n",
       "      <td>6.442155</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6.063900</td>\n",
       "      <td>6.405957</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.992700</td>\n",
       "      <td>6.359440</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.830500</td>\n",
       "      <td>6.451211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.437200</td>\n",
       "      <td>6.518744</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.704600</td>\n",
       "      <td>6.593138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.363600</td>\n",
       "      <td>6.655827</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.982400</td>\n",
       "      <td>6.702018</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.246500</td>\n",
       "      <td>6.687897</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.937900</td>\n",
       "      <td>6.684688</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>6.688070</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing Dataset Test Metrics: {\n",
      "    \"eval_loss\": 6.8842644691467285,\n",
      "    \"eval_accuracy\": 0.0033333333333333335,\n",
      "    \"eval_runtime\": 0.5222,\n",
      "    \"eval_samples_per_second\": 574.479,\n",
      "    \"eval_steps_per_second\": 19.149,\n",
      "    \"epoch\": 10.0\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [440/440 01:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.411500</td>\n",
       "      <td>6.158587</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.924700</td>\n",
       "      <td>5.877350</td>\n",
       "      <td>0.023333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.761000</td>\n",
       "      <td>5.573070</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.595200</td>\n",
       "      <td>5.407591</td>\n",
       "      <td>0.073333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.924700</td>\n",
       "      <td>5.317563</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.653200</td>\n",
       "      <td>5.359495</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.576900</td>\n",
       "      <td>5.143600</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.613700</td>\n",
       "      <td>4.974955</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.183100</td>\n",
       "      <td>4.741476</td>\n",
       "      <td>0.193333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.467400</td>\n",
       "      <td>4.674329</td>\n",
       "      <td>0.236667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.430100</td>\n",
       "      <td>4.382252</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.022200</td>\n",
       "      <td>4.122030</td>\n",
       "      <td>0.313333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.039300</td>\n",
       "      <td>4.005790</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.036700</td>\n",
       "      <td>4.348379</td>\n",
       "      <td>0.346667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.841600</td>\n",
       "      <td>3.846942</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.854400</td>\n",
       "      <td>3.661548</td>\n",
       "      <td>0.396667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.813100</td>\n",
       "      <td>3.317243</td>\n",
       "      <td>0.456667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.311900</td>\n",
       "      <td>3.238112</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.861700</td>\n",
       "      <td>3.019743</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.600600</td>\n",
       "      <td>2.787756</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>2.583840</td>\n",
       "      <td>0.596667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.561400</td>\n",
       "      <td>2.417055</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.167500</td>\n",
       "      <td>2.383724</td>\n",
       "      <td>0.636667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>2.349144</td>\n",
       "      <td>0.626667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>2.211763</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>2.150498</td>\n",
       "      <td>0.676667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>2.154918</td>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>2.095060</td>\n",
       "      <td>0.663333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>2.029828</td>\n",
       "      <td>0.686667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>2.005125</td>\n",
       "      <td>0.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>1.950470</td>\n",
       "      <td>0.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.922554</td>\n",
       "      <td>0.696667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.904654</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.886121</td>\n",
       "      <td>0.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.874705</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.867260</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.864006</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.861621</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.860458</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.858920</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.858710</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.858093</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.857824</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.857905</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Dataset Test Metrics: {\n",
      "    \"eval_loss\": 2.086529016494751,\n",
      "    \"eval_accuracy\": 0.72,\n",
      "    \"eval_runtime\": 0.6617,\n",
      "    \"eval_samples_per_second\": 453.399,\n",
      "    \"eval_steps_per_second\": 15.113,\n",
      "    \"epoch\": 10.0\n",
      "}\n",
      "##########Starting training cycle 2##########\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 00:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>1.826211</td>\n",
       "      <td>0.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>1.642709</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>1.663232</td>\n",
       "      <td>0.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>1.765351</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>1.740225</td>\n",
       "      <td>0.676667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.718524</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.635458</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.611056</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.597606</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.592664</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.589420</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.588258</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.588070</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing Dataset Test Metrics: {\n",
      "    \"eval_loss\": 1.767072319984436,\n",
      "    \"eval_accuracy\": 0.67,\n",
      "    \"eval_runtime\": 0.5504,\n",
      "    \"eval_samples_per_second\": 545.024,\n",
      "    \"eval_steps_per_second\": 18.167,\n",
      "    \"epoch\": 10.0\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [440/440 01:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>1.517927</td>\n",
       "      <td>0.723333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>1.377827</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>1.412158</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>1.414697</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>1.509931</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>1.604105</td>\n",
       "      <td>0.713333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>1.665180</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.224300</td>\n",
       "      <td>1.737814</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>1.675216</td>\n",
       "      <td>0.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>1.525567</td>\n",
       "      <td>0.723333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>1.562329</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>1.666789</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>1.518524</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>1.456278</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>1.402004</td>\n",
       "      <td>0.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>1.461265</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>1.410448</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>1.386986</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>1.298769</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>1.212099</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>1.233481</td>\n",
       "      <td>0.843333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.215097</td>\n",
       "      <td>0.846667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.210126</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.170157</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.142085</td>\n",
       "      <td>0.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.139303</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.152932</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.154136</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.151133</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.145119</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.142779</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.141806</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.140782</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.139840</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.139513</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.138494</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.138297</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.138180</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.137728</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.137563</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.137476</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.137377</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.137171</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.137492</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Dataset Test Metrics: {\n",
      "    \"eval_loss\": 1.2202895879745483,\n",
      "    \"eval_accuracy\": 0.8333333333333334,\n",
      "    \"eval_runtime\": 0.5245,\n",
      "    \"eval_samples_per_second\": 571.959,\n",
      "    \"eval_steps_per_second\": 19.065,\n",
      "    \"epoch\": 10.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from json import dumps\n",
    "\n",
    "CICLES = 2\n",
    "sep = \"#\" * 10\n",
    "for ci in range(CICLES):\n",
    "    print(f\"{sep}Starting training cycle {ci + 1}{sep}\")\n",
    "    trainer_indexing.train()\n",
    "    metrics_indexing = trainer_indexing.evaluate(eval_dataset=tokenized_datasets_query[\"test\"])\n",
    "    print(f\"Indexing Dataset Test Metrics: {dumps(metrics_indexing, indent=4)}\")\n",
    "    trainer_query.train()\n",
    "    metrics_query = trainer_query.evaluate(eval_dataset=tokenized_datasets_query[\"test\"])\n",
    "    print(f\"Query Dataset Test Metrics: {dumps(metrics_query, indent=4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf27958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set for query dataset...\n",
      "Query Dataset Test Metrics: {\n",
      "    \"eval_loss\": 1.2202895879745483,\n",
      "    \"eval_accuracy\": 0.8333333333333334,\n",
      "    \"eval_runtime\": 0.5681,\n",
      "    \"eval_samples_per_second\": 528.035,\n",
      "    \"eval_steps_per_second\": 17.601,\n",
      "    \"epoch\": 10.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test final\n",
    "from json import dumps\n",
    "print(\"Evaluating on test set for query dataset...\")\n",
    "metrics_query = trainer_query.evaluate(eval_dataset=tokenized_datasets_query[\"test\"])\n",
    "print(f\"Query Dataset Test Metrics: {dumps(metrics_query, indent=4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f3988ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set for query dataset...\n",
      "Sample query: ¿Cómo puedo contactar con Hugo Castro?\n",
      "Real label for the first test query: 7557_4\n",
      "Predicted label for query '¿Cómo puedo contactar con Hugo Castro?': 7557_4\n",
      "Top 20 predictions:\n",
      "Label: 7557_4, Probability: 0.9890\n",
      "Label: 7502_4, Probability: 0.0026\n",
      "Label: 7507_5, Probability: 0.0017\n",
      "Label: 7536_1, Probability: 0.0012\n",
      "Label: 7577_2, Probability: 0.0012\n",
      "Label: 7552_4, Probability: 0.0008\n",
      "Label: 7571_2, Probability: 0.0004\n",
      "Label: 7504_1, Probability: 0.0004\n",
      "Label: 7553_1, Probability: 0.0004\n",
      "Label: 7558_1, Probability: 0.0003\n",
      "Label: 7507_4, Probability: 0.0002\n",
      "Label: 7552_5, Probability: 0.0002\n",
      "Label: 7539_4, Probability: 0.0002\n",
      "Label: 7574_4, Probability: 0.0002\n",
      "Label: 7571_5, Probability: 0.0002\n",
      "Label: 7505_3, Probability: 0.0001\n",
      "Label: 7541_5, Probability: 0.0001\n",
      "Label: 7530_5, Probability: 0.0001\n",
      "Label: 7547_3, Probability: 0.0000\n",
      "Label: 7540_2, Probability: 0.0000\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# testea la salida de una pregunta, me refiero a obtener la predicción\n",
    "\n",
    "print(\"Evaluating on test set for query dataset...\")\n",
    "index = 100\n",
    "query = tokenized_datasets_query[\"test\"][index][\"text\"]\n",
    "real_label_id = tokenized_datasets_query[\"test\"][index][\"label\"]\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "real_label = id_to_label[real_label_id]\n",
    "print(f\"Sample query: {query}\")\n",
    "print(f\"Real label for the first test query: {real_label}\")\n",
    "inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH)\n",
    "inputs = {k: v.to(trainer_query.model.device) for k, v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    outputs = trainer_query.model(**inputs)\n",
    "logits = outputs.logits\n",
    "predicted_class_id = logits.argmax().item()\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "predicted_label = id_to_label[predicted_class_id]\n",
    "print(f\"Predicted label for query '{query}': {predicted_label}\")\n",
    "# extra los top k prediciones con mayor probabilidad\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "top_k = 20\n",
    "top_k_probs, top_k_indices = torch.topk(probs, top_k)\n",
    "print(f\"Top {top_k} predictions:\")\n",
    "for prob, idx in zip(top_k_probs[0], top_k_indices[0]):\n",
    "    label = id_to_label[idx.item()]\n",
    "    print(f\"Label: {label}, Probability: {prob.item():.4f}\")\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea4cb616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:17<00:00, 17.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# me gustaria que me hicieras un bucle con la logica de la celda anterior para ver si no acierta alguna muestra me diga que posicion esta en la lista de logits\n",
    "from tqdm import tqdm\n",
    "\n",
    "labels_predicted = []\n",
    "labels_real = []\n",
    "\n",
    "for index in tqdm(range(len(tokenized_datasets_query[\"test\"]))):\n",
    "    query = tokenized_datasets_query[\"test\"][index][\"text\"]\n",
    "    real_label_id = tokenized_datasets_query[\"test\"][index][\"label\"]\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "    real_label = id_to_label[real_label_id]\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH)\n",
    "    inputs = {k: v.to(trainer_query.model.device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = trainer_query.model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    # get list of labels sorted by probability\n",
    "    sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "    sorted_labels = [id_to_label[idx.item()] for idx in sorted_indices[0]]\n",
    "\n",
    "    labels_predicted.append(sorted_labels)\n",
    "    labels_real.append([real_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6baf6c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking Metrics:\n",
      "  MRR: 0.8557\n",
      "  mAP: 0.8557\n",
      "  AvgRank: 16.0200\n",
      "  CMC@1: 0.8333\n",
      "  Recall@k (macro)@1: 0.8333\n",
      "  Precision@k (macro)@1: 0.8333\n",
      "  Accuracy@1: 0.8333\n",
      "  F1@k (macro)@1: 0.8333\n",
      "  CMC@5: 0.8800\n",
      "  Recall@k (macro)@5: 0.8800\n",
      "  Precision@k (macro)@5: 0.1760\n",
      "  Accuracy@5: 0.8800\n",
      "  F1@k (macro)@5: 0.2933\n",
      "  CMC@10: 0.8900\n",
      "  Recall@k (macro)@10: 0.8900\n",
      "  Precision@k (macro)@10: 0.0890\n",
      "  Accuracy@10: 0.8900\n",
      "  F1@k (macro)@10: 0.1618\n",
      "  CMC@20: 0.9000\n",
      "  Recall@k (macro)@20: 0.9000\n",
      "  Precision@k (macro)@20: 0.0450\n",
      "  Accuracy@20: 0.9000\n",
      "  F1@k (macro)@20: 0.0857\n",
      "  CMC@100: 0.9467\n",
      "  Recall@k (macro)@100: 0.9467\n",
      "  Precision@k (macro)@100: 0.0095\n",
      "  Accuracy@100: 0.9467\n",
      "  F1@k (macro)@100: 0.0187\n"
     ]
    }
   ],
   "source": [
    "from ranking_metrics import calc_ranking_metrics\n",
    "\n",
    "metrics = calc_ranking_metrics(labels_predicted, labels_real, ks=[1, 5, 10, 20, 100], one_relevant_per_query=True)\n",
    "\n",
    "print(\"Ranking Metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d03f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
