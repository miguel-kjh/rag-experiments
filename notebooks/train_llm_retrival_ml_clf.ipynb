{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "02911839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, numpy as np, torch\n",
    "from datasets import load_dataset, ClassLabel\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from transformers import BitsAndBytesConfig\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8ee5bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 400/400 [00:00<00:00, 41216.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 400\n",
      "Labels: ['7500_1', '7500_2', '7500_3', '7500_4', '7500_5', '7501_1', '7501_2', '7501_3', '7501_4', '7501_5', '7502_1', '7502_2', '7502_3', '7502_4', '7502_5', '7503_1', '7503_2', '7503_3', '7503_4', '7503_5', '7504_1', '7504_2', '7504_3', '7504_4', '7504_5', '7505_1', '7505_2', '7505_3', '7505_4', '7505_5', '7506_1', '7506_2', '7506_3', '7506_4', '7506_5', '7507_1', '7507_2', '7507_3', '7507_4', '7507_5', '7508_1', '7508_2', '7508_3', '7508_4', '7508_5', '7509_1', '7509_2', '7509_3', '7509_4', '7509_5', '7510_1', '7510_2', '7510_3', '7510_4', '7510_5', '7511_1', '7511_2', '7511_3', '7511_4', '7511_5', '7512_1', '7512_2', '7512_3', '7512_4', '7512_5', '7513_1', '7513_2', '7513_3', '7513_4', '7513_5', '7514_1', '7514_2', '7514_3', '7514_4', '7514_5', '7515_1', '7515_2', '7515_3', '7515_4', '7515_5', '7516_1', '7516_2', '7516_3', '7516_4', '7516_5', '7517_1', '7517_2', '7517_3', '7517_4', '7517_5', '7518_1', '7518_2', '7518_3', '7518_4', '7518_5', '7519_1', '7519_2', '7519_3', '7519_4', '7519_5', '7520_1', '7520_2', '7520_3', '7520_4', '7520_5', '7521_1', '7521_2', '7521_3', '7521_4', '7521_5', '7522_1', '7522_2', '7522_3', '7522_4', '7522_5', '7523_1', '7523_2', '7523_3', '7523_4', '7523_5', '7524_1', '7524_2', '7524_3', '7524_4', '7524_5', '7525_1', '7525_2', '7525_3', '7525_4', '7525_5', '7526_1', '7526_2', '7526_3', '7526_4', '7526_5', '7527_1', '7527_2', '7527_3', '7527_4', '7527_5', '7528_1', '7528_2', '7528_3', '7528_4', '7528_5', '7529_1', '7529_2', '7529_3', '7529_4', '7529_5', '7530_1', '7530_2', '7530_3', '7530_4', '7530_5', '7531_1', '7531_2', '7531_3', '7531_4', '7531_5', '7532_1', '7532_2', '7532_3', '7532_4', '7532_5', '7533_1', '7533_2', '7533_3', '7533_4', '7533_5', '7534_1', '7534_2', '7534_3', '7534_4', '7534_5', '7535_1', '7535_2', '7535_3', '7535_4', '7535_5', '7536_1', '7536_2', '7536_3', '7536_4', '7536_5', '7537_1', '7537_2', '7537_3', '7537_4', '7537_5', '7538_1', '7538_2', '7538_3', '7538_4', '7538_5', '7539_1', '7539_2', '7539_3', '7539_4', '7539_5', '7540_1', '7540_2', '7540_3', '7540_4', '7540_5', '7541_1', '7541_2', '7541_3', '7541_4', '7541_5', '7542_1', '7542_2', '7542_3', '7542_4', '7542_5', '7543_1', '7543_2', '7543_3', '7543_4', '7543_5', '7544_1', '7544_2', '7544_3', '7544_4', '7544_5', '7545_1', '7545_2', '7545_3', '7545_4', '7545_5', '7546_1', '7546_2', '7546_3', '7546_4', '7546_5', '7547_1', '7547_2', '7547_3', '7547_4', '7547_5', '7548_1', '7548_2', '7548_3', '7548_4', '7548_5', '7549_1', '7549_2', '7549_3', '7549_4', '7549_5', '7550_1', '7550_2', '7550_3', '7550_4', '7550_5', '7551_1', '7551_2', '7551_3', '7551_4', '7551_5', '7552_1', '7552_2', '7552_3', '7552_4', '7552_5', '7553_1', '7553_2', '7553_3', '7553_4', '7553_5', '7554_1', '7554_2', '7554_3', '7554_4', '7554_5', '7555_1', '7555_2', '7555_3', '7555_4', '7555_5', '7556_1', '7556_2', '7556_3', '7556_4', '7556_5', '7557_1', '7557_2', '7557_3', '7557_4', '7557_5', '7558_1', '7558_2', '7558_3', '7558_4', '7558_5', '7559_1', '7559_2', '7559_3', '7559_4', '7559_5', '7560_1', '7560_2', '7560_3', '7560_4', '7560_5', '7561_1', '7561_2', '7561_3', '7561_4', '7561_5', '7562_1', '7562_2', '7562_3', '7562_4', '7562_5', '7563_1', '7563_2', '7563_3', '7563_4', '7563_5', '7564_1', '7564_2', '7564_3', '7564_4', '7564_5', '7565_1', '7565_2', '7565_3', '7565_4', '7565_5', '7566_1', '7566_2', '7566_3', '7566_4', '7566_5', '7567_1', '7567_2', '7567_3', '7567_4', '7567_5', '7568_1', '7568_2', '7568_3', '7568_4', '7568_5', '7569_1', '7569_2', '7569_3', '7569_4', '7569_5', '7570_1', '7570_2', '7570_3', '7570_4', '7570_5', '7571_1', '7571_2', '7571_3', '7571_4', '7571_5', '7572_1', '7572_2', '7572_3', '7572_4', '7572_5', '7573_1', '7573_2', '7573_3', '7573_4', '7573_5', '7574_1', '7574_2', '7574_3', '7574_4', '7574_5', '7575_1', '7575_2', '7575_3', '7575_4', '7575_5', '7576_1', '7576_2', '7576_3', '7576_4', '7576_5', '7577_1', '7577_2', '7577_3', '7577_4', '7577_5', '7578_1', '7578_2', '7578_3', '7578_4', '7578_5', '7579_1', '7579_2', '7579_3', '7579_4', '7579_5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 400/400 [00:00<00:00, 41410.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_indexing_csv = pd.read_csv(\"../notebooks/data/contacts_docs.csv\")\n",
    "\n",
    "# to dataset huggingface\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset_indexing = Dataset.from_pandas(dataset_indexing_csv)\n",
    "\n",
    "# create a new column 'text' that concatenates 'name', 'phone'\n",
    "def concatenate_columns(example):\n",
    "    return {\n",
    "        \"text\": f\"Nombre: {example['name']}\\nTeléfono: {example['phone']}\"\n",
    "    }\n",
    "dataset_indexing = dataset_indexing.map(concatenate_columns)\n",
    "# rename column 'id' to 'label'\n",
    "dataset_indexing = dataset_indexing.rename_column(\"id\", \"label\")\n",
    "\n",
    "num_labels = len(dataset_indexing['label'])\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "labels_list = dataset_indexing.unique('label')\n",
    "print(f\"Labels: {labels_list}\")\n",
    "\n",
    "# map labels to integers\n",
    "label_to_id = {label: i for i, label in enumerate(labels_list)}\n",
    "def map_labels(example):\n",
    "    return {\n",
    "        \"label\": label_to_id[example['label']]\n",
    "    }\n",
    "dataset_indexing = dataset_indexing.map(map_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df77002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dataset_train = pd.read_csv(\"../notebooks/data/contacts_queries_train.csv\")\n",
    "query_dataset_val = pd.read_csv(\"../notebooks/data/contacts_queries_val.csv\")\n",
    "query_dataset_test = pd.read_csv(\"../notebooks/data/contacts_queries_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "88962b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1400/1400 [00:00<00:00, 60355.90 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 60787.01 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 52006.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '¿Cómo puedo contactar con Antonio Alonso?', 'label': 194}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_for_queries = {\n",
    "    \"train\": Dataset.from_pandas(query_dataset_train),\n",
    "    \"validation\": Dataset.from_pandas(query_dataset_val),\n",
    "    \"test\": Dataset.from_pandas(query_dataset_test)\n",
    "}\n",
    "\n",
    "for split in dataset_for_queries:\n",
    "    dataset_for_queries[split] = dataset_for_queries[split].rename_column(\"question\", \"text\")\n",
    "    dataset_for_queries[split] = dataset_for_queries[split].rename_column(\"id\", \"label\")\n",
    "    # map labels to integers\n",
    "    dataset_for_queries[split] = dataset_for_queries[split].map(map_labels)\n",
    "\n",
    "# to dataset huggingface\n",
    "from datasets import DatasetDict\n",
    "dataset_for_queries = DatasetDict(dataset_for_queries)\n",
    "print(dataset_for_queries[\"train\"][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1107a838",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "19767e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c4f1a9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-0.6B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b372807",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_r = 256\n",
    "lora_alpha = lora_r * 2\n",
    "lora_dropout = 0.0\n",
    "lora_bias = \"none\"\n",
    "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"up_proj\", \"down_proj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f23ba430",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    inference_mode=False,\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=lora_bias,\n",
    "    target_modules=target_modules\n",
    ")\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c43bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.base_model.model.score.parameters():\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "579c201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 400/400 [00:00<00:00, 49456.76 examples/s]\n",
      "Map: 100%|██████████| 1400/1400 [00:00<00:00, 84155.38 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 45981.77 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 46804.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=MAX_LENGTH, padding=False)\n",
    "\n",
    "# tokenize test from dataset\n",
    "tokenized_datasets_indexing = dataset_indexing.map(preprocess, batched=True)\n",
    "tokenized_datasets_query = dataset_for_queries.map(preprocess, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1c2db441",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=8)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = (preds == labels).mean()\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3585bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "SEED = 42\n",
    "EPOCHS = 10\n",
    "training_args_indexing = TrainingArguments(\n",
    "    output_dir=f\"models/contacts_clf_{model_name.replace('/', '_')}_indexing\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"steps\",     # o \"no\" si no vas a evaluar\n",
    "    save_strategy=\"no\",        # <-- no guarda checkpoints ni el modelo final\n",
    "    eval_steps=10,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=False,  # <-- desactivado porque no hay checkpoints\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "training_args_query = TrainingArguments(\n",
    "    output_dir=f\"models/contacts_clf_{model_name.replace('/', '_')}_query\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"no\",        # <-- no guarda checkpoints ni el modelo final\n",
    "    eval_steps=10,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=False,  # <-- desactivado porque no hay checkpoints\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# IDs de tokens\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.bos_token_id = tokenizer.bos_token_id\n",
    "\n",
    "trainer_indexing = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_indexing,\n",
    "    train_dataset=tokenized_datasets_indexing,\n",
    "    eval_dataset=tokenized_datasets_query[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_query = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_query,\n",
    "    train_dataset=tokenized_datasets_query[\"train\"],\n",
    "    eval_dataset=tokenized_datasets_query[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8bc5c22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 132,939,776 || all params: 728,989,696 || trainable%: 18.2362\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()  # Verificar parámetros entrenables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "044ea9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########Starting training cycle 1##########\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 00:23, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.820000</td>\n",
       "      <td>7.252311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.229000</td>\n",
       "      <td>6.664512</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.140500</td>\n",
       "      <td>6.520859</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6.067700</td>\n",
       "      <td>6.372051</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.944700</td>\n",
       "      <td>6.377181</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.653700</td>\n",
       "      <td>6.398425</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.030700</td>\n",
       "      <td>6.477132</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.011000</td>\n",
       "      <td>6.465443</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.269300</td>\n",
       "      <td>6.500814</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.097800</td>\n",
       "      <td>6.513555</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.601100</td>\n",
       "      <td>6.509596</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.306900</td>\n",
       "      <td>6.521165</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>6.523177</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing Dataset Test Metrics: {\n",
      "    \"eval_loss\": 6.562037944793701,\n",
      "    \"eval_accuracy\": 0.01,\n",
      "    \"eval_runtime\": 0.4657,\n",
      "    \"eval_samples_per_second\": 644.145,\n",
      "    \"eval_steps_per_second\": 21.471,\n",
      "    \"epoch\": 10.0\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [440/440 01:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.365700</td>\n",
       "      <td>6.036188</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.698400</td>\n",
       "      <td>5.464395</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.156000</td>\n",
       "      <td>5.172052</td>\n",
       "      <td>0.106667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.911700</td>\n",
       "      <td>5.079490</td>\n",
       "      <td>0.143333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.622200</td>\n",
       "      <td>4.880845</td>\n",
       "      <td>0.153333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.354100</td>\n",
       "      <td>4.778047</td>\n",
       "      <td>0.186667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.249900</td>\n",
       "      <td>4.662904</td>\n",
       "      <td>0.193333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.163900</td>\n",
       "      <td>4.533704</td>\n",
       "      <td>0.223333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.756600</td>\n",
       "      <td>4.360244</td>\n",
       "      <td>0.243333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.300200</td>\n",
       "      <td>4.203339</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.216200</td>\n",
       "      <td>3.927417</td>\n",
       "      <td>0.326667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.858000</td>\n",
       "      <td>3.897518</td>\n",
       "      <td>0.336667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.062900</td>\n",
       "      <td>3.730794</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.321100</td>\n",
       "      <td>4.118407</td>\n",
       "      <td>0.396667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.183600</td>\n",
       "      <td>3.717635</td>\n",
       "      <td>0.403333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.250500</td>\n",
       "      <td>3.595461</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.255700</td>\n",
       "      <td>3.301464</td>\n",
       "      <td>0.423333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.623500</td>\n",
       "      <td>3.606020</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.293700</td>\n",
       "      <td>3.541684</td>\n",
       "      <td>0.443333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.001400</td>\n",
       "      <td>3.145049</td>\n",
       "      <td>0.486667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.936800</td>\n",
       "      <td>2.971087</td>\n",
       "      <td>0.543333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>2.806873</td>\n",
       "      <td>0.546667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>2.702406</td>\n",
       "      <td>0.563333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>2.605755</td>\n",
       "      <td>0.596667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.278500</td>\n",
       "      <td>2.537626</td>\n",
       "      <td>0.636667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>2.417439</td>\n",
       "      <td>0.653333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>2.323980</td>\n",
       "      <td>0.653333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>2.257647</td>\n",
       "      <td>0.673333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>2.262589</td>\n",
       "      <td>0.653333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>2.206372</td>\n",
       "      <td>0.686667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>2.127558</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>2.086611</td>\n",
       "      <td>0.696667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>2.056128</td>\n",
       "      <td>0.713333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>2.026801</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>2.021288</td>\n",
       "      <td>0.723333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>2.018059</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>2.017557</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>2.016592</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>2.015742</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>2.014670</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>2.014264</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.014186</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>2.013508</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.013755</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Dataset Test Metrics: {\n",
      "    \"eval_loss\": 2.2265539169311523,\n",
      "    \"eval_accuracy\": 0.6966666666666667,\n",
      "    \"eval_runtime\": 0.5194,\n",
      "    \"eval_samples_per_second\": 577.64,\n",
      "    \"eval_steps_per_second\": 19.255,\n",
      "    \"epoch\": 10.0\n",
      "}\n",
      "##########Starting training cycle 2##########\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 00:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>1.922221</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.246200</td>\n",
       "      <td>1.971110</td>\n",
       "      <td>0.686667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>1.954503</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>2.012406</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>1.960125</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.998994</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>1.972437</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.954031</td>\n",
       "      <td>0.713333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.948961</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.943881</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.941957</td>\n",
       "      <td>0.713333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.941181</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.940604</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing Dataset Test Metrics: {\n",
      "    \"eval_loss\": 1.9097065925598145,\n",
      "    \"eval_accuracy\": 0.7166666666666667,\n",
      "    \"eval_runtime\": 0.4852,\n",
      "    \"eval_samples_per_second\": 618.322,\n",
      "    \"eval_steps_per_second\": 20.611,\n",
      "    \"epoch\": 10.0\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [440/440 01:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.861472</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.747326</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.779034</td>\n",
       "      <td>0.736667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>1.808843</td>\n",
       "      <td>0.736667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>1.986957</td>\n",
       "      <td>0.713333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>2.198146</td>\n",
       "      <td>0.663333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.274700</td>\n",
       "      <td>2.150442</td>\n",
       "      <td>0.673333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.339800</td>\n",
       "      <td>1.931464</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>1.939975</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>1.974955</td>\n",
       "      <td>0.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>1.953348</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>1.989017</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>1.838690</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>1.773129</td>\n",
       "      <td>0.763333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>1.817890</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>1.753162</td>\n",
       "      <td>0.756667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>1.731908</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>1.686291</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>1.546695</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.456635</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>1.486967</td>\n",
       "      <td>0.796667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>1.481379</td>\n",
       "      <td>0.806667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.457443</td>\n",
       "      <td>0.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.441950</td>\n",
       "      <td>0.823333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.427233</td>\n",
       "      <td>0.823333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.388675</td>\n",
       "      <td>0.836667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.383485</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.383598</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.379808</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.374702</td>\n",
       "      <td>0.836667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.372989</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.372299</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.371962</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.372129</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.372084</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.372535</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.372088</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.372619</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.371953</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.371926</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.372227</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.371876</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.372113</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.372135</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Dataset Test Metrics: {\n",
      "    \"eval_loss\": 1.410375714302063,\n",
      "    \"eval_accuracy\": 0.8433333333333334,\n",
      "    \"eval_runtime\": 0.441,\n",
      "    \"eval_samples_per_second\": 680.332,\n",
      "    \"eval_steps_per_second\": 22.678,\n",
      "    \"epoch\": 10.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from json import dumps\n",
    "\n",
    "CICLES = 2\n",
    "sep = \"#\" * 10\n",
    "for ci in range(CICLES):\n",
    "    print(f\"{sep}Starting training cycle {ci + 1}{sep}\")\n",
    "    trainer_indexing.train()\n",
    "    metrics_indexing = trainer_indexing.evaluate(eval_dataset=tokenized_datasets_query[\"test\"])\n",
    "    print(f\"Indexing Dataset Test Metrics: {dumps(metrics_indexing, indent=4)}\")\n",
    "    trainer_query.train()\n",
    "    metrics_query = trainer_query.evaluate(eval_dataset=tokenized_datasets_query[\"test\"])\n",
    "    print(f\"Query Dataset Test Metrics: {dumps(metrics_query, indent=4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cf27958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set for query dataset...\n",
      "Query Dataset Test Metrics: {\n",
      "    \"eval_loss\": 1.410375714302063,\n",
      "    \"eval_accuracy\": 0.8433333333333334,\n",
      "    \"eval_runtime\": 0.4568,\n",
      "    \"eval_samples_per_second\": 656.671,\n",
      "    \"eval_steps_per_second\": 21.889,\n",
      "    \"epoch\": 10.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test final\n",
    "from json import dumps\n",
    "print(\"Evaluating on test set for query dataset...\")\n",
    "metrics_query = trainer_query.evaluate(eval_dataset=tokenized_datasets_query[\"test\"])\n",
    "print(f\"Query Dataset Test Metrics: {dumps(metrics_query, indent=4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
