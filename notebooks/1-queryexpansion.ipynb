{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f25489ee",
   "metadata": {},
   "source": [
    "### Query Enhancement – Query Expansion Techniques\n",
    "\n",
    "In a RAG pipeline, the quality of the query sent to the retriever determines how good the retrieved context is — and therefore, how accurate the LLM’s final answer will be.\n",
    "\n",
    "That’s where Query Expansion / Enhancement comes in.\n",
    "\n",
    "#### 🎯 What is Query Enhancement?\n",
    "Query enhancement refers to techniques used to improve or reformulate the user query to retrieve better, more relevant documents from the knowledge base.\n",
    "It is especially useful when:\n",
    "\n",
    "- The original query is short, ambiguous, or under-specified\n",
    "- You want to broaden the scope to catch synonyms, related phrases, or spelling variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff6ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/miniconda3/envs/RAG/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbe7b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 5\n",
    "TOP_J = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "410d3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step1 : Load and split the dataset\n",
    "loader = TextLoader(\"langchain_crewai_dataset.txt\")\n",
    "raw_docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(raw_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1885ba57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v1)\"), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v1)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v2)\"), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v2)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v3)\"), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v3)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v4)\"), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v4)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v5)\"), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v5)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v6)\"), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v6)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v7)\"), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v7)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v8)\"), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v8)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v9)\"), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v9)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another.'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and dynamically communicating with one another. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v10)\"), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v10)'), Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v10)')]\n"
     ]
    }
   ],
   "source": [
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1365028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic splitter\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={\"device\": \"cuda\"})\n",
    "splitter = SemanticChunker(embedding_model)\n",
    "chunks = splitter.split_documents(raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "791ba3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "984258ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "def build_faiss_with_progress(docs, embedding_model, batch_size=32, normalize=True):\n",
    "    \"\"\"\n",
    "    Construye un índice FAISS desde documentos mostrando una barra de progreso.\n",
    "\n",
    "    Args:\n",
    "        docs (List[Document]): Lista de documentos de LangChain.\n",
    "        embedding_model: Instancia de HuggingFaceEmbeddings u otro modelo compatible.\n",
    "        batch_size (int): Tamaño de lote para embeddings.\n",
    "        normalize (bool): Si normalizar embeddings (coseno). Equivale a normalize_L2=True.\n",
    "\n",
    "    Returns:\n",
    "        FAISS: Vectorstore listo para usar como retriever.\n",
    "    \"\"\"\n",
    "    texts = [d.page_content for d in docs]\n",
    "    embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generando embeddings\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        batch_emb = embedding_model.embed_documents(batch)\n",
    "        embeddings.extend(batch_emb)\n",
    "\n",
    "    # Crear FAISS desde embeddings precomputados\n",
    "    vectorstore = FAISS.from_embeddings(\n",
    "        list(zip(texts, embeddings)),\n",
    "        embedding=embedding_model,\n",
    "        normalize_L2=normalize\n",
    "    )\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f001ff8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando embeddings: 100%|██████████| 16/16 [00:00<00:00, 16.69it/s]\n"
     ]
    }
   ],
   "source": [
    "### step 2: Vector Store\n",
    "embedding_model=HuggingFaceEmbeddings(\n",
    "    model_name=\"google/embeddinggemma-300m\",\n",
    "    model_kwargs={\"device\": \"cuda\"}  # <--- GPU\n",
    ")\n",
    "vectorstore=build_faiss_with_progress(chunks, embedding_model, batch_size=16, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c1d32c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='0f50d9d6-94c7-4477-a6de-290c72f58064', metadata={}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(id='fd5a8ad4-e16f-4a62-a403-e2f3e1e5b072', metadata={}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v1)'), Document(id='a4d7fc71-7c7f-4f4c-8a2d-ccdb41bd639e', metadata={}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(id='10898b80-3986-4a51-85be-40cb7983be2a', metadata={}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v1)'), Document(id='c9056e33-8049-45fd-afdf-0d82948802d9', metadata={}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(id='fa8e8630-ff69-42b5-a526-34e9b5466528', metadata={}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v1)'), Document(id='bf1b4bec-074c-4016-81e4-07f52aab4ccc', metadata={}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v1)'), Document(id='d679e927-48ad-43ad-a302-94e9ab764571', metadata={}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(id='5753fa84-ad58-4fd5-86c5-ee583a775509', metadata={}, page_content='like web search, calculators, code execution environments, and custom APIs. (v1)'), Document(id='18df19d7-f321-483c-88dc-7e94a5c3fa80', metadata={}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v1)'), Document(id='4745b881-4fe7-4bec-8d45-82ef3ee51136', metadata={}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v1)'), Document(id='769d9f3e-7a59-423d-83a3-d64ab2e5cce4', metadata={}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v1)'), Document(id='dcf88283-cdf8-477b-ade5-dc52587c751e', metadata={}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v1)'), Document(id='3314a95d-07e3-4769-96c2-93dd76c0b77e', metadata={}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v1)'), Document(id='0d9f614e-3b5e-4c44-b1e9-6793cb3b19c2', metadata={}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v1)'), Document(id='4d2015a4-79e2-43fa-bd5d-2fabb20e9e2c', metadata={}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v1)'), Document(id='97fa0fee-1493-4c47-bc7c-ccfce4419ebf', metadata={}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v1)'), Document(id='d0249fac-fe71-43e7-9323-a103792afd51', metadata={}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v1)\"), Document(id='9e2d876c-8f13-49ad-a506-865829f7e711', metadata={}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v1)'), Document(id='7417f708-fdcb-4e29-9b1c-729aff1fc2a0', metadata={}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v1)'), Document(id='cbfa1089-677c-4977-bc43-609ee73937b8', metadata={}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v1)'), Document(id='91937d90-5a13-44b5-9b53-4cfe055adf33', metadata={}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v1)'), Document(id='44de4955-8af8-4eca-8fc0-2104d92f4f72', metadata={}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v1)'), Document(id='47f96c12-c558-4163-9ec7-108789bc4057', metadata={}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v1)'), Document(id='726b7621-a03a-4295-a77a-2b8e6adf53f6', metadata={}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(id='82f396c3-1de6-4fce-81d8-d050476e55f3', metadata={}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v2)'), Document(id='e0ba07c1-afac-4740-b15e-d30c3f2a8c78', metadata={}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(id='36da2ea5-ca72-4893-8ada-b2e2c2c198df', metadata={}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v2)'), Document(id='30f5e84a-7819-430a-8614-1e61afce8b75', metadata={}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(id='fc009522-b62e-45b9-b433-7e2b4681f5be', metadata={}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v2)'), Document(id='356a6b45-7f11-4e2b-8aba-946768be9d25', metadata={}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v2)'), Document(id='5a614988-5ffd-4e80-ad80-5d4e5492a771', metadata={}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(id='a57428d8-6000-4962-a9e5-4c764d2f343b', metadata={}, page_content='like web search, calculators, code execution environments, and custom APIs. (v2)'), Document(id='09c6db3f-f0c0-4cb0-92fc-0647f542b2f0', metadata={}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v2)'), Document(id='1942bce9-0dad-4a1e-83e9-dd372986fde4', metadata={}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v2)'), Document(id='258c83f2-6ad9-4520-9573-9b27c5af079c', metadata={}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v2)'), Document(id='5b7b8f9a-c2a1-4873-913f-9cb116c25dae', metadata={}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v2)'), Document(id='2624b2e1-73d7-4727-8123-29a6ab34d35e', metadata={}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v2)'), Document(id='8688b237-7d77-467f-8227-516e95ac2a4f', metadata={}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v2)'), Document(id='4bcb72f4-7818-4078-9215-dcffcde02c66', metadata={}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v2)'), Document(id='3b61258d-2f32-4948-a027-1c5ba6b798ab', metadata={}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v2)'), Document(id='ff525a10-64c0-41da-95aa-01da8ea79f37', metadata={}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v2)\"), Document(id='4ce38e1f-8972-48bc-a43e-25adf2140124', metadata={}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v2)'), Document(id='2bd9f83e-b331-4636-bf00-29a50d9b067a', metadata={}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v2)'), Document(id='fcd89887-7d12-41e2-8a31-2eb8bdca72df', metadata={}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v2)'), Document(id='16d6a84b-9165-46a9-a66e-60d69e560305', metadata={}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v2)'), Document(id='433ab49b-a294-48cf-8704-0851e81fa810', metadata={}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v2)'), Document(id='4c527f1d-fe83-447f-b649-7063d9785df0', metadata={}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v2)'), Document(id='303e5d90-c464-4949-b827-d63569e53bad', metadata={}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(id='cc526d9d-313a-401b-8c40-0b3ca99b6245', metadata={}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v3)'), Document(id='b2e00d33-acf7-49ae-ae15-1f6dfaa62f91', metadata={}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(id='e85a10c4-652d-421c-80ef-d8d87bc2543d', metadata={}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v3)'), Document(id='8aa73d2c-a02a-47e5-9d4d-d19a53fd3fde', metadata={}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(id='44d20cc7-f7e0-4156-9ab2-5958963593ad', metadata={}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v3)'), Document(id='4b001f13-93a2-45b8-bf26-76de2f2a487c', metadata={}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v3)'), Document(id='e8c75edf-913b-4329-891f-5bfb4c49239d', metadata={}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(id='cf1717d3-3276-4511-aaa3-75bb049d38b1', metadata={}, page_content='like web search, calculators, code execution environments, and custom APIs. (v3)'), Document(id='f11a6679-de5d-49de-9bee-dcdf5722adc6', metadata={}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v3)'), Document(id='590053b7-f0e7-4d3d-82cd-8406e2cb50a1', metadata={}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v3)'), Document(id='32db69e6-9a62-4dad-9fb4-7f1876cb7bcb', metadata={}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v3)'), Document(id='bcfa1e12-95a3-4428-ae4b-7f17b0aab8d3', metadata={}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v3)'), Document(id='81579235-1313-46f5-b2bc-ea1aad1c91cd', metadata={}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v3)'), Document(id='41f2690a-8dfd-4a84-99e3-ca8e4282489b', metadata={}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v3)'), Document(id='b9b3041e-ceb2-4c7f-b7ab-5bdb7b898733', metadata={}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v3)'), Document(id='e84adef8-6077-4c61-bc23-a0991dfd9d36', metadata={}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v3)'), Document(id='f43edc57-e86c-4c82-8d58-0294bfce65f5', metadata={}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v3)\"), Document(id='079b5396-bd3b-4914-a3ad-85f4f057eb87', metadata={}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v3)'), Document(id='7822e8ca-a57a-49bc-820b-0d6e38136ec5', metadata={}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v3)'), Document(id='1b6957ba-11b3-456f-80af-5c6921644d35', metadata={}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v3)'), Document(id='4b6ef4e8-412d-467d-94a9-cfa1eaa8e8e0', metadata={}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v3)'), Document(id='3479fd49-6905-4dfa-9911-a5979531cbb8', metadata={}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v3)'), Document(id='ea4bd089-7711-47e7-bcac-afd3393d55a8', metadata={}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v3)'), Document(id='a7f6776b-7708-4a1b-b7e5-359cf15dab78', metadata={}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(id='5f80a627-0f8a-4891-b06e-6fd38d8d3804', metadata={}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v4)'), Document(id='d8e2dc67-8eb1-4b9e-8854-04c1669ee068', metadata={}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(id='76feb665-ebba-4854-88b0-fd7a29e61f47', metadata={}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v4)'), Document(id='da3b8465-b773-4dc0-9c19-3cc37fc8f6ae', metadata={}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(id='01c13775-093d-417b-ae7d-a5ced180f60e', metadata={}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v4)'), Document(id='a32a9397-3ba6-417f-aece-a090b42fd49c', metadata={}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v4)'), Document(id='619afcd1-1370-4e63-b8ce-2bda2b32aa84', metadata={}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(id='6678565d-463e-4989-a064-5dfbed5d68cb', metadata={}, page_content='like web search, calculators, code execution environments, and custom APIs. (v4)'), Document(id='ac71e97d-70f0-4cd5-a885-4335b9ea9213', metadata={}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v4)'), Document(id='7e31cbbc-a744-4a30-974e-eda929516edc', metadata={}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v4)'), Document(id='1ca23ca4-1076-4524-a81a-ae0b15488a85', metadata={}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v4)'), Document(id='b19fb88d-c1e4-4706-a190-3844f2af4c1e', metadata={}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v4)'), Document(id='25f6672c-7f84-4e65-842a-83a6c9b1aed2', metadata={}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v4)'), Document(id='3c523978-72bd-455f-b3c6-7048dcc2de0d', metadata={}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v4)'), Document(id='066a494d-13e5-4c09-8640-2fda1545737a', metadata={}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v4)'), Document(id='224cfeb5-43ea-4ff8-9094-9e8c731113a4', metadata={}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v4)'), Document(id='9196a063-329f-46a9-b67d-3b688cdbdf7c', metadata={}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v4)\"), Document(id='62740fc6-6b0b-49ef-b0e5-0151334efd6b', metadata={}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v4)'), Document(id='99de0911-b1ff-47eb-b51c-9d063c94b4da', metadata={}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v4)'), Document(id='cd844089-fce8-4e57-8a11-99bd8a1e4e05', metadata={}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v4)'), Document(id='d8874d58-d60c-4830-8baf-107814d33e89', metadata={}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v4)'), Document(id='4163b7d5-b94f-41f7-a59d-659108fc8cef', metadata={}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v4)'), Document(id='fced5305-3a1b-45f0-ae54-c55d26b6dd3c', metadata={}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v4)'), Document(id='dae3347f-2491-43ed-a5ed-88560704c359', metadata={}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(id='ad1b4c80-19b7-474a-94c9-5a831e58d21b', metadata={}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v5)'), Document(id='06b3ff55-5124-4de6-a67e-4241f371d077', metadata={}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(id='66575464-9ddf-4b42-ae02-e79c8459fe57', metadata={}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v5)'), Document(id='d1551f57-85be-48d9-83fa-2d8c97e44345', metadata={}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(id='a2cf2947-9d98-4925-ade7-3f371a2a0dad', metadata={}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v5)'), Document(id='cd733005-87a5-425b-b882-9a8ee9705cc8', metadata={}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v5)'), Document(id='3e38e649-fecd-4805-beef-8e764e1ff5a2', metadata={}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(id='835f1dac-bcc1-4895-8c38-13921d01eae1', metadata={}, page_content='like web search, calculators, code execution environments, and custom APIs. (v5)'), Document(id='039156a9-ee0b-49c8-9b42-fd2089040436', metadata={}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v5)'), Document(id='6610f54c-614e-4ba5-b2f0-3692116c04f7', metadata={}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v5)'), Document(id='ce561d09-7685-4c4c-a4ec-f68d72420afe', metadata={}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v5)'), Document(id='e2d47acc-ee05-4b3f-aff9-b5bba19796b0', metadata={}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v5)'), Document(id='fa3b6fa0-4bf8-4903-a441-d641c54ae2e7', metadata={}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v5)'), Document(id='cac94794-8221-4d90-904e-fcf81fc61c13', metadata={}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v5)'), Document(id='07bcdb4c-12ef-4bd0-b1c6-58c1297de633', metadata={}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v5)'), Document(id='c8d5f6af-77ff-4a33-bcca-28b281831a04', metadata={}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v5)'), Document(id='5262c8b5-5cd4-4784-bcde-e2ffe4982e8f', metadata={}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v5)\"), Document(id='15e545ab-f1d5-4102-9949-12b6b4db3594', metadata={}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v5)'), Document(id='1be72b62-3581-48c4-844d-5621c592738f', metadata={}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v5)'), Document(id='f6f37329-4d92-4472-901e-f44aca314143', metadata={}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v5)'), Document(id='3ed081d5-ea8d-46d9-8d04-89b94f4c9dd8', metadata={}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v5)'), Document(id='3c58aef8-1624-4cfc-90bc-2ebc2d16ec99', metadata={}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v5)'), Document(id='51f5adcf-e088-4888-b447-7c7802f7364e', metadata={}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v5)'), Document(id='6a4b8c1d-b189-4d0e-884d-ea620f1d04d5', metadata={}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(id='f62c577e-6a19-48d4-9068-b624b6370fef', metadata={}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v6)'), Document(id='d3fb6735-0059-4526-b700-e8ac0f15bacd', metadata={}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(id='4cd3c92a-802d-47e2-a0f7-36ee2cb40b76', metadata={}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v6)'), Document(id='14c57025-213c-4b91-9122-a4a97eeab4ee', metadata={}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(id='e8bd5fcd-2d29-4002-a0b5-f2eb5f082f9b', metadata={}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v6)'), Document(id='8747219e-5dc7-4e6b-8b62-2790be8962a5', metadata={}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v6)'), Document(id='b2db47ea-307c-4e74-b33c-cce064b5768a', metadata={}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(id='b89780b7-1da1-4c0e-9ff3-53181676be9c', metadata={}, page_content='like web search, calculators, code execution environments, and custom APIs. (v6)'), Document(id='7bee0a34-3b28-4362-b874-cc5453f148ed', metadata={}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v6)'), Document(id='6a6d7ad7-6bcd-4108-bbd3-f111e3cbe993', metadata={}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v6)'), Document(id='4b597aee-b739-4e19-b001-a6f402f1d0e3', metadata={}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v6)'), Document(id='6b85b4ce-9d1c-4434-ac79-984faca1d920', metadata={}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v6)'), Document(id='0af61045-1323-4253-a934-21f092764290', metadata={}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v6)'), Document(id='53ba2376-6acd-4150-bb73-d30a3f0fa28e', metadata={}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v6)'), Document(id='9774dbef-2a86-4f2b-9d89-4d79e58fdb43', metadata={}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v6)'), Document(id='db54392e-0bb1-46fd-b623-6b86b9985356', metadata={}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v6)'), Document(id='5e0263c9-b47e-447f-aa47-4527c18c0f19', metadata={}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v6)\"), Document(id='53d44720-0ac5-4646-89a7-e81472b954f4', metadata={}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v6)'), Document(id='073702a8-feff-4052-84d2-a90b9acc639b', metadata={}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v6)'), Document(id='27805c6c-7104-4dbc-aecd-5eabea1cfa17', metadata={}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v6)'), Document(id='eef6b349-be99-4299-b05e-b7065d8737d6', metadata={}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v6)'), Document(id='9233a48c-c3a0-4241-8cbc-031bf49d2947', metadata={}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v6)'), Document(id='401a1f7b-fd5a-4f31-9f41-e8c9e5aaa293', metadata={}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v6)'), Document(id='7326f7cd-7e50-467e-99b3-9294793e118f', metadata={}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(id='c1d20370-b5a8-4213-8cf6-af7264dca8b4', metadata={}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v7)'), Document(id='a0802df5-2152-43b8-9b4f-5e8ef75749e8', metadata={}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(id='6f4c4f46-9e4b-479a-8804-26df7efbcaa6', metadata={}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v7)'), Document(id='77775699-047a-456d-81c6-92f40ec5c158', metadata={}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(id='a3940eba-f8ef-4046-a9ab-1f3b76f47b95', metadata={}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v7)'), Document(id='155e826c-331b-46aa-b6af-bb1a495e32b9', metadata={}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v7)'), Document(id='2ccf845a-5c81-45e9-bc86-bae8bf3d9a1c', metadata={}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(id='bc6b07c4-2a13-4fe3-990d-d4b54f97b511', metadata={}, page_content='like web search, calculators, code execution environments, and custom APIs. (v7)'), Document(id='78e7647e-b80d-4405-a7f2-4d52250a37b8', metadata={}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v7)'), Document(id='12063e7c-df1d-41bd-997e-e5c8e5401ab6', metadata={}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v7)'), Document(id='59e05abd-1de8-44fc-9c70-39ec6224e2d6', metadata={}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v7)'), Document(id='69183d77-400b-4aa1-8e40-f38157c54436', metadata={}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v7)'), Document(id='ab1ed247-105d-419c-8cdb-9fd45a772102', metadata={}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v7)'), Document(id='2891c4cd-74bd-4a09-9004-72461884d232', metadata={}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v7)'), Document(id='3a9e3500-19e6-4c2a-8499-54b60f9a120b', metadata={}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v7)'), Document(id='900b2a2d-7859-4570-a19a-b964ead90361', metadata={}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v7)'), Document(id='59b096c8-86bd-48c4-951c-84f3829590c0', metadata={}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v7)\"), Document(id='1750d5e4-e1ef-40ab-81e7-79761d51df85', metadata={}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v7)'), Document(id='6a9854a6-59c0-4da7-a460-386cf8834ba2', metadata={}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v7)'), Document(id='c97f7cd7-c2a7-4c50-97f5-93ec12e5cbef', metadata={}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v7)'), Document(id='0b297897-e8c9-4140-b41e-6ffd68bc7e06', metadata={}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v7)'), Document(id='9e5b9fff-c061-4046-8016-57f844938cd1', metadata={}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v7)'), Document(id='0b9f371c-169f-43d0-bdff-b0a3d5441170', metadata={}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v7)'), Document(id='a2916676-0698-4dac-832b-27ff0bcf5b6a', metadata={}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(id='ba7ca99c-743e-4535-b3a5-a339a7ff9c0f', metadata={}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v8)'), Document(id='b2c28b01-05ad-4a80-bed7-4ea6b8d9c9db', metadata={}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(id='46f32b44-78ee-41b8-86bd-db8035ae08ca', metadata={}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v8)'), Document(id='04345085-feff-4ea5-bd8b-949d230768c1', metadata={}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(id='54996dcd-e3ed-46f7-b532-ed7f09b5df43', metadata={}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v8)'), Document(id='d3561fbd-317c-4bfd-a73b-4e3dabf20b77', metadata={}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v8)'), Document(id='dca9d16e-9b7e-461e-ba82-eee0850f7a45', metadata={}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(id='d767f0bd-b73a-4010-970a-7a960c1b6436', metadata={}, page_content='like web search, calculators, code execution environments, and custom APIs. (v8)'), Document(id='5943ca67-ffb3-4e87-a9f3-758d3266482d', metadata={}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v8)'), Document(id='f486aa18-e946-45cb-97ef-49c467a4c723', metadata={}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v8)'), Document(id='b40be8c9-4121-4dad-a477-efe3af195385', metadata={}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v8)'), Document(id='78ba896c-6415-4990-84d2-2a2c457f2120', metadata={}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v8)'), Document(id='700314f7-f3cf-462f-b178-053e80547739', metadata={}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v8)'), Document(id='0bff0172-435b-4673-9a1b-14dec0fa855b', metadata={}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v8)'), Document(id='048c60d8-14b7-4d5a-b393-270af98c8cd9', metadata={}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v8)'), Document(id='576bf83b-fbcb-4da8-9b8b-3a8b84db6d46', metadata={}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v8)'), Document(id='778dd4c8-0a69-4957-b82b-cd463834f843', metadata={}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v8)\"), Document(id='c51de5dc-1429-429e-94e4-a8d2d8d660c8', metadata={}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v8)'), Document(id='a06b74f7-974f-400e-89f8-426a8b34b201', metadata={}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v8)'), Document(id='301bcdec-b2c9-4c1c-b64f-adcf7972832f', metadata={}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v8)'), Document(id='c33db5de-59b0-45d3-800d-4cfbd272256a', metadata={}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v8)'), Document(id='20c07ebf-db6a-4b19-8759-4537aa3fc7ef', metadata={}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v8)'), Document(id='2f822b7f-9f18-465c-aef0-01f8233eef82', metadata={}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v8)'), Document(id='4e79169a-e066-48e7-9e62-8201cb38a395', metadata={}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(id='99cf9e6e-752b-429e-8a01-49531e6dda58', metadata={}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v9)'), Document(id='92266749-6ab1-4716-8290-675d2eb04abc', metadata={}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(id='0a6fc127-de0b-46d2-b27d-ed58ed823fc6', metadata={}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v9)'), Document(id='f94c0c0e-7b84-4411-853e-9268035b3469', metadata={}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(id='abbecb28-a021-47d3-8aa5-9295840bb0a8', metadata={}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v9)'), Document(id='fd28e73f-5a9e-4dc7-beaa-e6f700359f09', metadata={}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v9)'), Document(id='a7f7a74b-52d9-43ba-8cee-fc11bf9a283e', metadata={}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(id='1f6e4558-b961-425b-8eac-dc4a0642911f', metadata={}, page_content='like web search, calculators, code execution environments, and custom APIs. (v9)'), Document(id='336d5669-9e66-4c9c-a7af-e4a854c89c19', metadata={}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v9)'), Document(id='bf657035-bcf5-4516-a621-be1c652816c7', metadata={}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v9)'), Document(id='dfd0e1b5-c75b-47a2-9842-54609cb0e754', metadata={}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v9)'), Document(id='508ae36e-c14a-4bd9-8b87-182c175d6748', metadata={}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v9)'), Document(id='714f12fa-5f2a-4993-9616-466b54002d05', metadata={}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v9)'), Document(id='e41c3a0b-1da1-43cf-ae4c-7ee8d417d709', metadata={}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v9)'), Document(id='d1d1e223-5db9-4bdf-a8e8-d158a2451658', metadata={}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v9)'), Document(id='e9e509c9-503b-4487-811c-a2c386340d76', metadata={}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v9)'), Document(id='cefc8ed2-f79a-4c77-a015-f9f456732820', metadata={}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v9)\"), Document(id='05e64af9-eab9-4d72-a6c3-dd52b83937d1', metadata={}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v9)'), Document(id='63f6faff-3547-4d92-aaa2-7d5cc897eb84', metadata={}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v9)'), Document(id='5ad27050-587a-4f64-9f55-1da7772fe806', metadata={}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v9)'), Document(id='76db8fc5-8caf-4fb5-82d2-c07b1c274238', metadata={}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v9)'), Document(id='8f926c8c-e57d-4f04-b13f-5d306f27c958', metadata={}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v9)'), Document(id='9041313a-c90c-4b2d-b098-c565dd21bebe', metadata={}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v9)'), Document(id='f2a409d9-98f1-4871-885c-b33b5073950b', metadata={}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'), Document(id='299c813c-3786-4626-831d-d0a9bcb911a2', metadata={}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v10)'), Document(id='d4db8a73-4cc4-4815-8bbb-bdb1da1c42a0', metadata={}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'), Document(id='d2e29033-10b2-4cb4-ac05-1ed78b440e0d', metadata={}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v10)'), Document(id='1603a906-3439-4518-b5b9-c5d649890676', metadata={}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'), Document(id='fbee36f1-5f16-4840-8901-951d6b1153f7', metadata={}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v10)'), Document(id='0cde613a-183c-45cc-a2c4-a71638e12563', metadata={}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v10)'), Document(id='06068f77-472c-4090-b3ac-9cf87eef0f4f', metadata={}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'), Document(id='57bcdf9f-48ac-4131-8b2b-3fc17e2c04d8', metadata={}, page_content='like web search, calculators, code execution environments, and custom APIs. (v10)'), Document(id='309f7f33-b0da-4ae4-bd8b-bc9c1d759dbf', metadata={}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v10)'), Document(id='54af0f9f-0066-40e1-b833-277cdbe920ef', metadata={}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v10)'), Document(id='5b44aff9-2ae5-406f-96ba-9c49a122e9af', metadata={}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v10)'), Document(id='a87cf371-4295-4282-9df6-5087dc98429f', metadata={}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v10)'), Document(id='3f4e3c82-8e9f-4744-be32-4658aef74a6b', metadata={}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v10)'), Document(id='b6a870b9-bed5-4261-9c82-9c6feb1bd213', metadata={}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another.'), Document(id='bc159a3a-9085-4d81-a86e-923c2ac95275', metadata={}, page_content='and dynamically communicating with one another. (v10)'), Document(id='eb9cdf89-9acc-4fc9-a301-d8ae729adb12', metadata={}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v10)'), Document(id='346622c7-0526-4171-b01a-4ebc520be188', metadata={}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v10)'), Document(id='544fb66a-9b42-4a11-b57e-a7e96f38da6a', metadata={}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v10)\"), Document(id='f6a04477-4447-40a8-8ca5-ab79e10bf2ec', metadata={}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v10)'), Document(id='2b5d7d59-8a6b-496d-aefc-d01bd0c22061', metadata={}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v10)'), Document(id='f3c86be6-a5bf-4820-8292-4dd5282c1956', metadata={}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v10)'), Document(id='85549f0f-9bcc-44b8-9754-71e519e0b7a5', metadata={}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v10)'), Document(id='aed98fe9-623b-4699-81d6-125d42009871', metadata={}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v10)'), Document(id='a0838856-f4e9-4ac8-ba3b-e32d34e0d7c0', metadata={}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v10)')]\n"
     ]
    }
   ],
   "source": [
    "# get list of documents from vectorstore\n",
    "all_docs = vectorstore.docstore._dict.values()\n",
    "all_docs = list(all_docs)\n",
    "\n",
    "print(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "feb3461e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x70d67829fdd0>, search_kwargs={'k': 25})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## step 3:MMR Retriever\n",
    "retriever=vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":25})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aabd1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever, TFIDFRetriever \n",
    "\n",
    "sparse_retriever=TFIDFRetriever.from_documents(chunks)\n",
    "sparse_retriever.k=25 ##top-J documents to retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2e60fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "hybrid_retriever=EnsembleRetriever(\n",
    "    retrievers=[retriever,sparse_retriever],\n",
    "    weights=[0.7,0.3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4a7e107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 30\n",
      "page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution' metadata={'source': 'langchain_crewai_dataset.txt'}\n"
     ]
    }
   ],
   "source": [
    "candidates = hybrid_retriever.invoke(\"What is Langchain?\")\n",
    "print(f\"Number of candidates: {len(candidates)}\")\n",
    "print(candidates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9de06531",
   "metadata": {},
   "outputs": [],
   "source": [
    "## re-rank with cross-encoder\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "import numpy as np\n",
    "\n",
    "reranker  = CrossEncoder(\"BAAI/bge-reranker-large\", device=\"cuda\")\n",
    "\n",
    "def rerank_with_crossencoder(query, docs, top_k=5):\n",
    "    \"\"\"\n",
    "    Reordena documentos con un CrossEncoder.\n",
    "    \n",
    "    Args:\n",
    "        query (str): la consulta.\n",
    "        docs (List[Document]): lista de LangChain Document.\n",
    "        top_k (int): cuántos documentos devolver.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[Document, float]]: documentos ordenados con sus scores.\n",
    "    \"\"\"\n",
    "    # 2) Crear pares (query, documento)\n",
    "    pairs = [(query, d.page_content) for d in docs]\n",
    "\n",
    "    # 3) Obtener puntuaciones\n",
    "    scores = reranker.predict(pairs)\n",
    "\n",
    "    # 4) Ordenar por score descendente\n",
    "    ranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return ranked[:top_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7357d73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution\n",
      "-----\n",
      "LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM\n",
      "-----\n",
      "CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v9)\n",
      "-----\n",
      "CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v5)\n",
      "-----\n",
      "CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v6)\n",
      "-----\n",
      "CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v8)\n",
      "-----\n",
      "CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v4)\n",
      "-----\n",
      "CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v1)\n",
      "-----\n",
      "CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v3)\n",
      "-----\n",
      "and dynamically communicating with one another. (v10)\n",
      "-----\n",
      "like web search, calculators, code execution environments, and custom APIs. (v8)\n",
      "-----\n",
      "like web search, calculators, code execution environments, and custom APIs. (v4)\n",
      "-----\n",
      "like web search, calculators, code execution environments, and custom APIs. (v9)\n",
      "-----\n",
      "like web search, calculators, code execution environments, and custom APIs. (v6)\n",
      "-----\n",
      "like web search, calculators, code execution environments, and custom APIs. (v7)\n",
      "-----\n",
      "like web search, calculators, code execution environments, and custom APIs. (v5)\n",
      "-----\n",
      "like web search, calculators, code execution environments, and custom APIs. (v1)\n",
      "-----\n",
      "like web search, calculators, code execution environments, and custom APIs. (v3)\n",
      "-----\n",
      "like web search, calculators, code execution environments, and custom APIs. (v2)\n",
      "-----\n",
      "like web search, calculators, code execution environments, and custom APIs. (v10)\n",
      "-----\n",
      "easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v9)\n",
      "-----\n",
      "easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v7)\n",
      "-----\n",
      "easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v8)\n",
      "-----\n",
      "easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v1)\n",
      "-----\n",
      "and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v1)\n",
      "-----\n",
      "and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v9)\n",
      "-----\n",
      "easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v3)\n",
      "-----\n",
      "CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v7)\n",
      "-----\n",
      "CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v10)\n",
      "-----\n",
      "CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v2)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for c in candidates:\n",
    "    print(c.page_content)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "92c8b9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Score: 0.0337] and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v1)\n",
      "[Score: 0.0325] and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v9)\n",
      "[Score: 0.0169] One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution\n",
      "[Score: 0.0090] LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM\n",
      "[Score: 0.0060] like web search, calculators, code execution environments, and custom APIs. (v7)\n"
     ]
    }
   ],
   "source": [
    "# Re-rankear con cross-encoder\n",
    "reranked = rerank_with_crossencoder(\"What is Langchain?\", candidates, top_k=5)\n",
    "\n",
    "# Mostrar resultados\n",
    "for doc, score in reranked:\n",
    "    print(f\"[Score: {score:.4f}] {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d492cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a platform that allows developers to create end-to-end pipelines connecting Large Language Models (LLMs) with tools, APIs, vector databases, and other knowledge sources. It also supports agents that use LLMs to reason about tasks and execute multi-step processes. Additionally, LangChain integrates seamlessly with vector databases for semantic search within large document corpora.\n"
     ]
    }
   ],
   "source": [
    "# generar respuesta con LLM usando los documentos re-rankeados\n",
    "llm = init_chat_model(\"gpt-3.5-turbo\", temperature=0, max_tokens=512)\n",
    "prompt_template = \"\"\"Eres un asistente útil y preciso. Usa la siguiente información para responder a la pregunta al final.\n",
    "{context}\n",
    "Pregunta: {question}\n",
    "Respuesta:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    "    output_parser=StrOutputParser()\n",
    ")\n",
    "chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "response = chain.invoke({\n",
    "    \"context\": [doc for doc, score in reranked],\n",
    "    \"question\": \"What is Langchain?\"\n",
    "})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e8f2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7c421dd94550>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7c421dbe43d0>, root_client=<openai.OpenAI object at 0x7c421df73d50>, root_async_client=<openai.AsyncOpenAI object at 0x7c421dbe40d0>, model_name='o4-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## step 4 : LLM and Prompt\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm=init_chat_model(\"openai:o4-mini\")\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "116e2cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='\\nYou are a helpful assistant. Expand the following query to improve document retrieval by adding relevant synonyms, technical terms, and useful context.\\n\\nOriginal query: \"{query}\"\\n\\nExpanded query:\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7c421dd94550>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7c421dbe43d0>, root_client=<openai.OpenAI object at 0x7c421df73d50>, root_async_client=<openai.AsyncOpenAI object at 0x7c421dbe40d0>, model_name='o4-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query expansion\n",
    "query_expansion_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant. Expand the following query to improve document retrieval by adding relevant synonyms, technical terms, and useful context.\n",
    "\n",
    "Original query: \"{query}\"\n",
    "\n",
    "Expanded query:\n",
    "\"\"\")\n",
    "\n",
    "query_expansion_chain=query_expansion_prompt| llm | StrOutputParser()\n",
    "query_expansion_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d629dd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“LangChain memory” OR “Lang Chain memory management” OR “Langchain conversational memory” OR “persistent context storage” OR “stateful agent memory” OR “session storage for LLMs” OR “memory modules” OR “memory backends” OR “ConversationBufferMemory” OR “ConversationSummaryMemory” OR “EntityMemory” OR “CombinedMemory” OR “memory store” OR “vector memory store” OR “Redis memory” OR “SQLite memory” OR “in-memory cache” OR “retrieval-augmented generation” OR “chat history retrieval” OR “context window management” OR “LLM memory engineering” OR “Python LangChain memory examples”'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion_chain.invoke({\"query\":\"Langchain memory\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec6e3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG answering prompt\n",
    "answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm=llm,prompt=answer_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57e726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Full RAG pipeline with query expansion\n",
    "rag_pipeline = (\n",
    "    RunnableMap({\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"context\": lambda x: retriever.invoke(query_expansion_chain.invoke({\"query\": x[\"input\"]}))\n",
    "    })\n",
    "    | document_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddebe80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded query:\n",
      "“(LangChain OR “Lang Chain”) AND (“memory support” OR memory OR “memory module” OR “conversational memory” OR “session memory” OR context OR “state management” OR “context persistence”) AND (types OR categories OR implementations OR modules OR backends OR patterns OR architectures) AND (examples OR e.g. OR such as OR including) AND (ConversationBufferMemory OR ConversationSummaryMemory OR CombinedMemory OR VectorStoreRetrieverMemory OR “external vector store” OR “knowledge base” OR Redis OR PostgreSQL OR Pinecone OR Chroma OR Milvus OR Weaviate) AND (ephemeral OR persistent OR summary OR buffer OR retrieval‐augmented)\n",
      "✅ Answer:\n",
      " LangChain currently ships two “plug-and-play” memory back-ends for chat-based agents:\n",
      "\n",
      "1. ConversationBufferMemory  \n",
      "   – Keeps a running buffer of the full back-and-forth.  \n",
      "2. ConversationSummaryMemory  \n",
      "   – Actively summarizes older turns into a concise recap to stay within token limits.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Run query\n",
    "query = {\"input\": \"What types of memory does LangChain support?\"}\n",
    "print(query_expansion_chain.invoke({\"query\":query}))\n",
    "response = rag_pipeline.invoke(query)\n",
    "print(\"✅ Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd86621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded query:\n",
      "\n",
      "(\"CrewAI agents\" OR \"Crew AI agents\" OR \"autonomous crew management agents\" OR \"AI-based crew coordination agents\" OR \"virtual crew assistants\" OR \"autonomous crew assistants\" OR \"crew management software agents\" OR \"AI crew scheduler\" OR \"mult i-agent system for crew planning\" OR \"agent-based modeling for crew assignment\" OR \"reinforcement learning crew scheduler\" OR \"distributed crew coordination agents\")  \n",
      "AND  \n",
      "(\"crew scheduling\" OR \"workforce management\" OR \"staff rostering\" OR \"resource allocation\" OR \"operations planning\")  \n",
      "AND  \n",
      "(\"airline crew\" OR \"maritime crew\" OR \"railway staff\" OR \"hospital nursing staff\" OR \"logistics teams\")  \n",
      "AND  \n",
      "(\"machine learning\" OR \"multi-agent systems (MAS)\" OR \"reinforcement learning\" OR \"natural language processing\" OR \"decentralized AI\" OR \"software agents architecture\")\n",
      "✅ Answer:\n",
      " CrewAI agents are semi-autonomous, role-based workers in a multi-agent system.  Key characteristics include:  \n",
      "• Defined Role – e.g. researcher, planner or executor  \n",
      "• Purpose & Goal – each agent has its own mission that feeds into the overall crew objective  \n",
      "• Toolset – a specified collection of APIs, data sources or utilities it can call on  \n",
      "• Structured Workflow – agents collaborate in orchestrated steps rather than acting in isolation  \n",
      "• Task Adherence – the framework monitors progress so every agent stays on-task and contributes meaningfully to the shared outcome.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Run query\n",
    "query = {\"input\": \"CrewAI agents?\"}\n",
    "print(query_expansion_chain.invoke({\"query\":query}))\n",
    "response = rag_pipeline.invoke(query)\n",
    "print(\"✅ Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03d32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
